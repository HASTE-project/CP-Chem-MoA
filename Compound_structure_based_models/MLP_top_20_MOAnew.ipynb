{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# read the SMILES-MoA data  \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('top_20_MOAs.txt', sep = '\\t')"
      ],
      "metadata": {
        "id": "bFuMZhuHOwK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change 20 MoAs to classes \n",
        "MOA_class_dictionary = {'EGFR inhibitor': 8,\n",
        " 'HDAC inhibitor': 16,\n",
        " 'PI3K inhibitor': 13,\n",
        " 'acetylcholine receptor agonist': 1,\n",
        " 'acetylcholine receptor antagonist': 4,\n",
        " 'adrenergic receptor agonist': 18,\n",
        " 'adrenergic receptor antagonist': 15,\n",
        " 'bacterial cell wall synthesis inhibitor': 14,\n",
        " 'benzodiazepine receptor agonist': 10,\n",
        " 'calcium channel blocker': 5,\n",
        " 'cyclooxygenase inhibitor': 6,\n",
        " 'dopamine receptor antagonist': 12,\n",
        " 'glucocorticoid receptor agonist': 9,\n",
        " 'glutamate receptor antagonist': 19,\n",
        " 'histamine receptor antagonist': 17,\n",
        " 'phosphodiesterase inhibitor': 3,\n",
        " 'serotonin receptor agonist': 7,\n",
        " 'serotonin receptor antagonist': 2,\n",
        " 'sodium channel blocker': 11,\n",
        " 'topoisomerase inhibitor': 0}"
      ],
      "metadata": {
        "id": "17c5-JuGBwb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add classes column \n",
        "df['classes'] = None\n",
        "for i in range(df.shape[0]):\n",
        "  df.iloc[i,2] = MOA_class_dictionary[df.iloc[i,1]]"
      ],
      "metadata": {
        "id": "lF5D5wb6CRCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xowg0CstLlC-"
      },
      "outputs": [],
      "source": [
        "# split out the test set  \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_valid, x_test, y_train_valid, y_test = train_test_split(df.SMILES, df.classes, test_size =10/100,\n",
        " stratify = df.classes, shuffle = True, random_state = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLlcRhSeU6xW"
      },
      "outputs": [],
      "source": [
        "# kfold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits = 9)\n",
        "skf.get_n_splits(np.array(list(x_train_valid)), np.array(list(y_train_valid)))\n",
        "train_index_list = []\n",
        "valid_index_list = []\n",
        "for train_index, valid_index in skf.split(np.array(list(x_train_valid)), np.array(list(y_train_valid))):\n",
        "  train_index_list.append(train_index)\n",
        "  valid_index_list.append(valid_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOFIJo5MEMT0"
      },
      "outputs": [],
      "source": [
        "number_of_kfold = 0      # change the number from 0-8 to get 9 shuffles\n",
        "x_train = list(np.array(list(x_train_valid))[train_index_list[ number_of_kfold ]])\n",
        "x_valid = list(np.array(list(x_train_valid))[valid_index_list[ number_of_kfold ]])\n",
        "y_train = list(np.array(list(y_train_valid))[train_index_list[ number_of_kfold ]])\n",
        "y_valid = list(np.array(list(y_train_valid))[valid_index_list[ number_of_kfold ]])\n",
        "x_test = list(x_test)\n",
        "y_test = list(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0OPr-gtR8sj"
      },
      "outputs": [],
      "source": [
        "# turn to cannoical smiles\n",
        "import rdkit\n",
        "import numpy as np\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "x_train = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_train]\n",
        "x_valid = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_valid]\n",
        "x_test = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB4WWi8wKB59"
      },
      "outputs": [],
      "source": [
        "# change SMILES to Morgan Fingerprints \n",
        "def smiles_to_array(smiles):\n",
        "  molecules = Chem.MolFromSmiles(smiles) \n",
        "  fingerprints = AllChem.GetMorganFingerprintAsBitVect(molecules, 2)\n",
        "  x_array = []\n",
        "  arrays = np.zeros(0,)\n",
        "  DataStructs.ConvertToNumpyArray(fingerprints, arrays)\n",
        "  x_array.append(arrays)\n",
        "  x_array = np.asarray(x_array)\n",
        "  x_array = ((np.squeeze(x_array)).astype(int)) \n",
        "  return x_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6Fy6iGdLSVP"
      },
      "outputs": [],
      "source": [
        "# get the training set \n",
        "train_x = np.zeros((len(x_train), 2048), dtype = np.float32)\n",
        "for f in range(train_x.shape[0]):\n",
        "  train_x[f] = smiles_to_array(x_train[f])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKhQc7EOKHMM"
      },
      "outputs": [],
      "source": [
        "# get the validation set \n",
        "valid_x = np.zeros((len(x_valid), 2048), dtype = np.float32)\n",
        "for f in range(valid_x.shape[0]):\n",
        "  valid_x[f] = smiles_to_array(x_valid[f])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSJBpQREMRYr"
      },
      "outputs": [],
      "source": [
        "# get the test set \n",
        "test_x = np.zeros((len(x_test), 2048), dtype = np.float32)\n",
        "for f in range(test_x.shape[0]):\n",
        "  test_x[f] = smiles_to_array(x_test[f])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "557ApFkFa6j7"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(y_train).astype(int)\n",
        "y_valid = np.array(y_valid).astype(int)\n",
        "y_test = np.array(y_test).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlcQEfe9M-VV"
      },
      "outputs": [],
      "source": [
        "# create class weights\n",
        "from sklearn.utils import class_weight\n",
        "y_unique = np.unique(np.array(y_train))\n",
        "class_weights = class_weight.compute_class_weight(class_weight = 'balanced', classes = y_unique,\n",
        "                y = np.array(y_train)) \n",
        "class_weights_dict45 = dict(enumerate(class_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta8ysiFqNkpJ"
      },
      "outputs": [],
      "source": [
        "# set the architecture of model      \n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "num = len(set(df.MOA.tolist()))\n",
        "input1 = Input(shape=(train_x.shape[1],))\n",
        "layer = Dense(64, activation='relu')(input1)\n",
        "layer = Dropout(0.85)(layer)\n",
        "layer = Dense(num, activation='softmax')(layer)\n",
        "model1 = Model(inputs = input1, outputs = layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooDkEyMsNwkP"
      },
      "outputs": [],
      "source": [
        "# set the checkpoint   \n",
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath_mlp = '/content/'+'MLP_20_MOA_weights.hdf5'\n",
        "checkpoint_mlp = ModelCheckpoint(filepath_mlp, monitor='val_accuracy', verbose=0, save_best_only = True,\n",
        "                mode = 'max')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dt90GZzfOBar"
      },
      "outputs": [],
      "source": [
        "# compile the model \n",
        "model1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4),\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFbTVo2qkIJh"
      },
      "outputs": [],
      "source": [
        "# train the model \n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=25, verbose=0, mode='min')  \n",
        "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                  factor=0.1, patience=7, verbose=0, min_delta=1e-119, mode='min')\n",
        "history = model1.fit(train_x, y_train, validation_data=(valid_x, y_valid), class_weight=class_weights_dict45,\n",
        "            shuffle=True, verbose=2, epochs=1800, batch_size=64,\n",
        "            callbacks=[earlyStopping, checkpoint_mlp, reduce_lr_loss])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "from keras.models import load_model\n",
        "best_model = load_model(filepath_mlp)"
      ],
      "metadata": {
        "id": "iGHXy6V2gONJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScVSLvv4fDv-"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model \n",
        "from sklearn.metrics import classification_report\n",
        "assert list(y_test)[0:5] == [14, 12, 6, 13, 14]\n",
        "print(classification_report(y_test, np.array(best_model.predict(test_x).argmax(-1)),))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnTRonUbnyqb"
      },
      "outputs": [],
      "source": [
        "# print out training curves\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc = 'upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# References\n",
        "# https://future-chem.com/rdkit-google-colab/#toc5\n",
        "# https://www.rdkit.org/docs/index.html"
      ],
      "metadata": {
        "id": "dmteC1TiiXFE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}