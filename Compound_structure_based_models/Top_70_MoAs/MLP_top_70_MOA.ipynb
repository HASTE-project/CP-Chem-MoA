{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75-UZEGR1A0b"
      },
      "outputs": [],
      "source": [
        "# install rdkit  \n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y -c rdkit rdkit python=3.7\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "import pprint     \n",
        "pprint.pprint(sys.path)\n",
        "!python -c \"import site; print (site.getsitepackages())\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('top_70_MOAs.txt', sep = '\\t')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "O9GYJo2v9Zu9",
        "outputId": "301bbceb-4d5a-4171-e345-765526c6ac15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 SMILES  \\\n",
              "0                       Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1   \n",
              "1                  OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N   \n",
              "2           O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12   \n",
              "3            O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1   \n",
              "4     O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...   \n",
              "...                                                 ...   \n",
              "2312  CCn1c(nc2c(ncc(OC[C@H]3CCCNC3)c12)C#CC(C)(C)O)...   \n",
              "2313                CCN(CC)CCCCN1c2ccccc2Oc2ccc(Cl)cc12   \n",
              "2314      CCCCCCCCCCCCCCCCCCOP(O)(=O)OC1CC[N+](C)(C)CC1   \n",
              "2315  Cc1n[nH]c2ccc(cc12)-c1cncc(OC[C@@H](N)Cc2ccccc...   \n",
              "2316  CC(C)NC[C@@H](C(=O)N1CCN(CC1)c1ncnc2[C@@H](O)C...   \n",
              "\n",
              "                                 MOA  \n",
              "0     adrenergic receptor antagonist  \n",
              "1     adrenergic receptor antagonist  \n",
              "2     adrenergic receptor antagonist  \n",
              "3     adrenergic receptor antagonist  \n",
              "4     adrenergic receptor antagonist  \n",
              "...                              ...  \n",
              "2312                   AKT inhibitor  \n",
              "2313                   AKT inhibitor  \n",
              "2314                   AKT inhibitor  \n",
              "2315                   AKT inhibitor  \n",
              "2316                   AKT inhibitor  \n",
              "\n",
              "[2317 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52cecbee-3fc7-4cc8-b338-5ca8608d4ff0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2312</th>\n",
              "      <td>CCn1c(nc2c(ncc(OC[C@H]3CCCNC3)c12)C#CC(C)(C)O)...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2313</th>\n",
              "      <td>CCN(CC)CCCCN1c2ccccc2Oc2ccc(Cl)cc12</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2314</th>\n",
              "      <td>CCCCCCCCCCCCCCCCCCOP(O)(=O)OC1CC[N+](C)(C)CC1</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2315</th>\n",
              "      <td>Cc1n[nH]c2ccc(cc12)-c1cncc(OC[C@@H](N)Cc2ccccc...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2316</th>\n",
              "      <td>CC(C)NC[C@@H](C(=O)N1CCN(CC1)c1ncnc2[C@@H](O)C...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2317 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52cecbee-3fc7-4cc8-b338-5ca8608d4ff0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52cecbee-3fc7-4cc8-b338-5ca8608d4ff0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52cecbee-3fc7-4cc8-b338-5ca8608d4ff0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the duplicates \n",
        "for i in df.SMILES.tolist():\n",
        "  if df.SMILES.tolist().count(i) != 1:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "6S0Cz1ly_sZk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MOA_class_dictionary = {'AKT inhibitor': 4,\n",
        " 'ATPase inhibitor': 56,\n",
        " 'Aurora kinase inhibitor': 16,\n",
        " 'CC chemokine receptor antagonist': 33,\n",
        " 'CDK inhibitor': 18,\n",
        " 'DNA inhibitor': 63,\n",
        " 'DNA synthesis inhibitor': 26,\n",
        " 'EGFR inhibitor': 53,\n",
        " 'GABA receptor antagonist': 49,\n",
        " 'HCV inhibitor': 0,\n",
        " 'HDAC inhibitor': 22,\n",
        " 'HSP inhibitor': 6,\n",
        " 'JAK inhibitor': 27,\n",
        " 'MEK inhibitor': 37,\n",
        " 'NFkB pathway inhibitor': 3,\n",
        " 'PARP inhibitor': 43,\n",
        " 'PI3K inhibitor': 51,\n",
        " 'PPAR receptor agonist': 58,\n",
        " 'acetylcholine receptor agonist': 44,\n",
        " 'acetylcholine receptor antagonist': 36,\n",
        " 'acetylcholinesterase inhibitor': 19,\n",
        " 'adenosine receptor agonist': 45,\n",
        " 'adenosine receptor antagonist': 65,\n",
        " 'adrenergic receptor agonist': 69,\n",
        " 'adrenergic receptor antagonist': 15,\n",
        " 'angiotensin converting enzyme inhibitor': 8,\n",
        " 'antioxidant': 10,\n",
        " 'apoptosis stimulant': 20,\n",
        " 'bacterial 30S ribosomal subunit inhibitor': 13,\n",
        " 'bacterial 50S ribosomal subunit inhibitor': 17,\n",
        " 'bacterial DNA gyrase inhibitor': 31,\n",
        " 'bacterial cell wall synthesis inhibitor': 30,\n",
        " 'benzodiazepine receptor agonist': 57,\n",
        " 'bromodomain inhibitor': 59,\n",
        " 'calcium channel blocker': 35,\n",
        " 'carbonic anhydrase inhibitor': 50,\n",
        " 'cyclooxygenase inhibitor': 47,\n",
        " 'cytochrome P450 inhibitor': 12,\n",
        " 'dopamine receptor agonist': 54,\n",
        " 'dopamine receptor antagonist': 14,\n",
        " 'tachykinin antagonist': 28,\n",
        " 'estrogen receptor agonist': 52,\n",
        " 'glucocorticoid receptor agonist': 29,\n",
        " 'glutamate receptor agonist': 9,\n",
        " 'glutamate receptor antagonist': 34,\n",
        " 'histamine receptor agonist': 39,\n",
        " 'histamine receptor antagonist': 23,\n",
        " 'histone lysine methyltransferase inhibitor': 21,\n",
        " 'local anesthetic': 41,\n",
        " 'mTOR inhibitor': 62,\n",
        " 'monoamine oxidase inhibitor': 42,\n",
        " 'nitric oxide synthase inhibitor': 66,\n",
        " 'opioid receptor agonist': 40,\n",
        " 'opioid receptor antagonist': 55,\n",
        " 'p38 MAPK inhibitor': 11,\n",
        " 'phosphodiesterase inhibitor': 46,\n",
        " 'potassium channel activator': 1,\n",
        " 'potassium channel blocker': 68,\n",
        " 'progesterone receptor agonist': 67,\n",
        " 'prostanoid receptor antagonist': 48,\n",
        " 'protein synthesis inhibitor': 25,\n",
        " 'purinergic receptor antagonist': 61,\n",
        " 'radiopaque medium': 5,\n",
        " 'retinoid receptor agonist': 60,\n",
        " 'rho associated kinase inhibitor': 2,\n",
        " 'serotonin receptor agonist': 7,\n",
        " 'serotonin receptor antagonist': 32,\n",
        " 'sodium channel blocker': 38,\n",
        " 'topoisomerase inhibitor': 64,\n",
        " 'tubulin polymerization inhibitor': 24}  "
      ],
      "metadata": {
        "id": "17c5-JuGBwb0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_classes = list(MOA_class_dictionary.values())\n",
        "sorted_classes.sort() \n",
        "assert sorted_classes == [i for i in range(70)]"
      ],
      "metadata": {
        "id": "NkFqARR_B72C"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add classes column \n",
        "df['classes'] = None\n",
        "for i in range(df.shape[0]):\n",
        "  df.iloc[i,2] = MOA_class_dictionary[df.iloc[i,1]]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lF5D5wb6CRCn",
        "outputId": "53e99e5d-cf12-4bd5-db59-18da02931a52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 SMILES  \\\n",
              "0                       Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1   \n",
              "1                  OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N   \n",
              "2           O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12   \n",
              "3            O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1   \n",
              "4     O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...   \n",
              "...                                                 ...   \n",
              "2312  CCn1c(nc2c(ncc(OC[C@H]3CCCNC3)c12)C#CC(C)(C)O)...   \n",
              "2313                CCN(CC)CCCCN1c2ccccc2Oc2ccc(Cl)cc12   \n",
              "2314      CCCCCCCCCCCCCCCCCCOP(O)(=O)OC1CC[N+](C)(C)CC1   \n",
              "2315  Cc1n[nH]c2ccc(cc12)-c1cncc(OC[C@@H](N)Cc2ccccc...   \n",
              "2316  CC(C)NC[C@@H](C(=O)N1CCN(CC1)c1ncnc2[C@@H](O)C...   \n",
              "\n",
              "                                 MOA classes  \n",
              "0     adrenergic receptor antagonist      15  \n",
              "1     adrenergic receptor antagonist      15  \n",
              "2     adrenergic receptor antagonist      15  \n",
              "3     adrenergic receptor antagonist      15  \n",
              "4     adrenergic receptor antagonist      15  \n",
              "...                              ...     ...  \n",
              "2312                   AKT inhibitor       4  \n",
              "2313                   AKT inhibitor       4  \n",
              "2314                   AKT inhibitor       4  \n",
              "2315                   AKT inhibitor       4  \n",
              "2316                   AKT inhibitor       4  \n",
              "\n",
              "[2317 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a66f488d-e87d-4202-a004-0f01b74eee49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2312</th>\n",
              "      <td>CCn1c(nc2c(ncc(OC[C@H]3CCCNC3)c12)C#CC(C)(C)O)...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2313</th>\n",
              "      <td>CCN(CC)CCCCN1c2ccccc2Oc2ccc(Cl)cc12</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2314</th>\n",
              "      <td>CCCCCCCCCCCCCCCCCCOP(O)(=O)OC1CC[N+](C)(C)CC1</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2315</th>\n",
              "      <td>Cc1n[nH]c2ccc(cc12)-c1cncc(OC[C@@H](N)Cc2ccccc...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2316</th>\n",
              "      <td>CC(C)NC[C@@H](C(=O)N1CCN(CC1)c1ncnc2[C@@H](O)C...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2317 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a66f488d-e87d-4202-a004-0f01b74eee49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a66f488d-e87d-4202-a004-0f01b74eee49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a66f488d-e87d-4202-a004-0f01b74eee49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A function that changes smiles string to fingerprints \n",
        "import rdkit\n",
        "import numpy as np\n",
        "from rdkit import *\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "def smiles_to_array_to_string(smiles):\n",
        "  molecules = Chem.MolFromSmiles(smiles) \n",
        "  fingerprints = AllChem.GetMorganFingerprintAsBitVect(molecules, 2)\n",
        "  x_array = []\n",
        "  arrays  = np.zeros(0,)\n",
        "  DataStructs.ConvertToNumpyArray(fingerprints, arrays)\n",
        "  x_array.append(arrays)\n",
        "  x_array = np.asarray(x_array)\n",
        "  x_array = list((np.squeeze(x_array)).astype(int))\n",
        "  string = ''\n",
        "  for i in x_array:\n",
        "    string += str(i) \n",
        "  return string"
      ],
      "metadata": {
        "id": "RfbsXXcT_sb7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the existence of Isomers\n",
        "assert len(set([smiles_to_array_to_string(i) for i in df.SMILES.tolist()])) == df.shape[0]"
      ],
      "metadata": {
        "id": "1u3oVoqMFh94"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "CFagctK7GiTn",
        "outputId": "04782c2a-cf72-4cd5-f3a7-c58d082cfb32"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        SMILES  \\\n",
              "0              Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1   \n",
              "1         OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N   \n",
              "2  O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12   \n",
              "\n",
              "                              MOA classes  \n",
              "0  adrenergic receptor antagonist      15  \n",
              "1  adrenergic receptor antagonist      15  \n",
              "2  adrenergic receptor antagonist      15  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-679cf7cc-8e0b-4408-820a-2c0d469abd25\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-679cf7cc-8e0b-4408-820a-2c0d469abd25')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-679cf7cc-8e0b-4408-820a-2c0d469abd25 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-679cf7cc-8e0b-4408-820a-2c0d469abd25');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xowg0CstLlC-"
      },
      "outputs": [],
      "source": [
        "# Split out the test set  \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_valid, x_test, y_train_valid, y_test = train_test_split(df.SMILES, df.classes, test_size =10/100,\n",
        " stratify = df.classes, shuffle = True, random_state = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BLlcRhSeU6xW"
      },
      "outputs": [],
      "source": [
        "# kfold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits = 9)\n",
        "skf.get_n_splits(np.array(list(x_train_valid)), np.array(list(y_train_valid)))\n",
        "train_index_list = []\n",
        "valid_index_list = []\n",
        "for train_index, valid_index in skf.split(np.array(list(x_train_valid)), np.array(list(y_train_valid))):\n",
        "  train_index_list.append(train_index)\n",
        "  valid_index_list.append(valid_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_list = []\n",
        "for i in range(9):\n",
        "  a_list += list(np.array(list(x_train_valid))[valid_index_list[i]])"
      ],
      "metadata": {
        "id": "JQT77vDlTeNy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DEqt9fUnDqBe"
      },
      "outputs": [],
      "source": [
        "number_of_kfold = 0 # change the number from 0-8 to get 9 shuffles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aOFIJo5MEMT0"
      },
      "outputs": [],
      "source": [
        "  x_train = list(np.array(list(x_train_valid))[train_index_list[ number_of_kfold ]])\n",
        "  x_valid = list(np.array(list(x_train_valid))[valid_index_list[ number_of_kfold ]])\n",
        "  y_train = list(np.array(list(y_train_valid))[train_index_list[ number_of_kfold ]])\n",
        "  y_valid = list(np.array(list(y_train_valid))[valid_index_list[ number_of_kfold ]])\n",
        "  x_test = list(x_test)\n",
        "  y_test = list(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "L0OPr-gtR8sj"
      },
      "outputs": [],
      "source": [
        "# turn to cannoical  smiles\n",
        "x_train = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_train]\n",
        "x_valid = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_valid]\n",
        "x_test = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZB4WWi8wKB59"
      },
      "outputs": [],
      "source": [
        "def smiles_to_array(smiles):\n",
        "  molecules = Chem.MolFromSmiles(smiles) \n",
        "  fingerprints = AllChem.GetMorganFingerprintAsBitVect(molecules, 2)\n",
        "  x_array = []\n",
        "  arrays = np.zeros(0,)\n",
        "  DataStructs.ConvertToNumpyArray(fingerprints, arrays)\n",
        "  x_array.append(arrays)\n",
        "  x_array = np.asarray(x_array)\n",
        "  x_array = ((np.squeeze(x_array)).astype(int)) \n",
        "  return x_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "a6Fy6iGdLSVP"
      },
      "outputs": [],
      "source": [
        "train_x = np.zeros((len(x_train), 2048), dtype = np.float32)\n",
        "for f in range(train_x.shape[0]):\n",
        "  train_x[f] = smiles_to_array(x_train[f])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dKhQc7EOKHMM"
      },
      "outputs": [],
      "source": [
        "valid_x = np.zeros((len(x_valid), 2048), dtype = np.float32)\n",
        "for f in range(valid_x.shape[0]):\n",
        "  valid_x[f] = smiles_to_array(x_valid[f])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "eSJBpQREMRYr"
      },
      "outputs": [],
      "source": [
        "test_x = np.zeros((len(x_test), 2048), dtype = np.float32)\n",
        "for f in range(test_x.shape[0]):\n",
        "  test_x[f] = smiles_to_array(x_test[f])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there are overlaps\n",
        "overlap = []\n",
        "for i in range(train_x.shape[0]):\n",
        "  for j in range(valid_x.shape[0]):\n",
        "    if np.array_equal(train_x[i], valid_x[j]) == True:\n",
        "      overlap.append((i,j))\n",
        "      print(i,j)"
      ],
      "metadata": {
        "id": "7rWxLD37banf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(test_x.shape[0]):\n",
        "  for j in range(valid_x.shape[0]):\n",
        "    if np.array_equal(test_x[i], valid_x[j]) == True:\n",
        "      overlap.append((i,j))\n",
        "      print(i,j)"
      ],
      "metadata": {
        "id": "gxflY746cryJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(train_x.shape[0]):\n",
        "  for j in range(test_x.shape[0]):\n",
        "    if np.array_equal(train_x[i], test_x[j]) == True:\n",
        "      overlap.append((i,j))\n",
        "      print(i,j)"
      ],
      "metadata": {
        "id": "hbAAMsqPcr0y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(overlap) == 0"
      ],
      "metadata": {
        "id": "YNCJ9YgpoLTV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "557ApFkFa6j7"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(y_train).astype(int)\n",
        "y_valid = np.array(y_valid).astype(int)\n",
        "y_test = np.array(y_test).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "eL24GiF7rCVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0654c32-e39c-4532-9789-dd9b20cc8bde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "477"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import gc               \n",
        "gc.collect() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KlcQEfe9M-VV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc9fbda-b978-4338-94f0-4667c431a365"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.6544642857142857,\n",
              " 1: 2.205952380952381,\n",
              " 2: 2.205952380952381,\n",
              " 3: 1.8908163265306122,\n",
              " 4: 2.036263736263736,\n",
              " 5: 2.205952380952381,\n",
              " 6: 1.393233082706767,\n",
              " 7: 0.5402332361516035,\n",
              " 8: 1.4706349206349207,\n",
              " 9: 1.3235714285714286,\n",
              " 10: 1.5571428571428572,\n",
              " 11: 1.7647619047619048,\n",
              " 12: 1.4706349206349207,\n",
              " 13: 1.4706349206349207,\n",
              " 14: 0.5190476190476191,\n",
              " 15: 0.34830827067669173,\n",
              " 16: 1.5571428571428572,\n",
              " 17: 1.8908163265306122,\n",
              " 18: 0.9804232804232804,\n",
              " 19: 1.3235714285714286,\n",
              " 20: 2.205952380952381,\n",
              " 21: 1.260544217687075,\n",
              " 22: 0.8539170506912442,\n",
              " 23: 0.47270408163265304,\n",
              " 24: 1.393233082706767,\n",
              " 25: 0.9454081632653061,\n",
              " 26: 1.260544217687075,\n",
              " 27: 1.4706349206349207,\n",
              " 28: 2.205952380952381,\n",
              " 29: 0.7154440154440155,\n",
              " 30: 0.35295238095238096,\n",
              " 31: 1.058857142857143,\n",
              " 32: 0.4812987012987013,\n",
              " 33: 1.1509316770186335,\n",
              " 34: 0.4411904761904762,\n",
              " 35: 0.7154440154440155,\n",
              " 36: 0.4010822510822511,\n",
              " 37: 1.5571428571428572,\n",
              " 38: 0.8539170506912442,\n",
              " 39: 2.205952380952381,\n",
              " 40: 1.393233082706767,\n",
              " 41: 1.393233082706767,\n",
              " 42: 1.3235714285714286,\n",
              " 43: 1.4706349206349207,\n",
              " 44: 0.7563265306122449,\n",
              " 45: 1.5571428571428572,\n",
              " 46: 0.5294285714285715,\n",
              " 47: 0.3350813743218807,\n",
              " 48: 1.7647619047619048,\n",
              " 49: 1.7647619047619048,\n",
              " 50: 1.8908163265306122,\n",
              " 51: 0.7785714285714286,\n",
              " 52: 1.393233082706767,\n",
              " 53: 0.8272321428571429,\n",
              " 54: 0.9454081632653061,\n",
              " 55: 1.7647619047619048,\n",
              " 56: 1.4706349206349207,\n",
              " 57: 0.912807881773399,\n",
              " 58: 1.393233082706767,\n",
              " 59: 1.5571428571428572,\n",
              " 60: 1.6544642857142857,\n",
              " 61: 1.7647619047619048,\n",
              " 62: 1.6544642857142857,\n",
              " 63: 2.036263736263736,\n",
              " 64: 0.912807881773399,\n",
              " 65: 1.2032467532467532,\n",
              " 66: 1.7647619047619048,\n",
              " 67: 1.7647619047619048,\n",
              " 68: 1.393233082706767,\n",
              " 69: 0.3950959488272921}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Create class weights\n",
        "from sklearn.utils import class_weight\n",
        "y_unique = np.unique(np.array(y_train))\n",
        "class_weights = class_weight.compute_class_weight(class_weight = 'balanced', classes = y_unique,\n",
        "                y = np.array(y_train)) \n",
        "class_weights_dict45 = dict(enumerate(class_weights))\n",
        "class_weights_dict45"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ta8ysiFqNkpJ"
      },
      "outputs": [],
      "source": [
        "# The architecture of model      \n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "num = len(set(df.MOA.tolist()))\n",
        "input1 = Input(shape=(train_x.shape[1],))\n",
        "layer = Dense(64, activation='relu')(input1)\n",
        "layer = Dropout(0.8)(layer)\n",
        "layer = Dense(num, activation='softmax')(layer)\n",
        "model1 = Model(inputs = input1, outputs = layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ooDkEyMsNwkP"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath_mlp = '/content/'+'MLP_70_MOA_weights.hdf5'\n",
        "checkpoint_mlp = ModelCheckpoint(filepath_mlp, monitor='val_accuracy', verbose=0, save_best_only = True,\n",
        "                mode = 'max')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Dt90GZzfOBar"
      },
      "outputs": [],
      "source": [
        "model1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4),\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "gFbTVo2qkIJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7562fc06-b476-44a3-bf0f-06b688134ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 - 3s - loss: 4.3102 - accuracy: 0.0146 - val_loss: 4.2656 - val_accuracy: 0.0172 - lr: 1.0000e-04 - 3s/epoch - 102ms/step\n",
            "Epoch 2/1800\n",
            "29/29 - 0s - loss: 4.2886 - accuracy: 0.0194 - val_loss: 4.2544 - val_accuracy: 0.0172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 3/1800\n",
            "29/29 - 0s - loss: 4.2689 - accuracy: 0.0140 - val_loss: 4.2446 - val_accuracy: 0.0216 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 4/1800\n",
            "29/29 - 0s - loss: 4.2657 - accuracy: 0.0151 - val_loss: 4.2352 - val_accuracy: 0.0302 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 5/1800\n",
            "29/29 - 0s - loss: 4.2392 - accuracy: 0.0221 - val_loss: 4.2262 - val_accuracy: 0.0388 - lr: 1.0000e-04 - 97ms/epoch - 3ms/step\n",
            "Epoch 6/1800\n",
            "29/29 - 0s - loss: 4.2151 - accuracy: 0.0200 - val_loss: 4.2180 - val_accuracy: 0.0560 - lr: 1.0000e-04 - 98ms/epoch - 3ms/step\n",
            "Epoch 7/1800\n",
            "29/29 - 0s - loss: 4.2043 - accuracy: 0.0243 - val_loss: 4.2096 - val_accuracy: 0.0647 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 8/1800\n",
            "29/29 - 0s - loss: 4.1846 - accuracy: 0.0216 - val_loss: 4.2017 - val_accuracy: 0.0733 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 9/1800\n",
            "29/29 - 0s - loss: 4.1831 - accuracy: 0.0237 - val_loss: 4.1942 - val_accuracy: 0.0819 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 10/1800\n",
            "29/29 - 0s - loss: 4.1711 - accuracy: 0.0286 - val_loss: 4.1854 - val_accuracy: 0.0991 - lr: 1.0000e-04 - 94ms/epoch - 3ms/step\n",
            "Epoch 11/1800\n",
            "29/29 - 0s - loss: 4.1529 - accuracy: 0.0383 - val_loss: 4.1780 - val_accuracy: 0.1078 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 12/1800\n",
            "29/29 - 0s - loss: 4.1290 - accuracy: 0.0443 - val_loss: 4.1690 - val_accuracy: 0.1164 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 13/1800\n",
            "29/29 - 0s - loss: 4.1145 - accuracy: 0.0475 - val_loss: 4.1600 - val_accuracy: 0.1250 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 14/1800\n",
            "29/29 - 0s - loss: 4.1196 - accuracy: 0.0426 - val_loss: 4.1512 - val_accuracy: 0.1509 - lr: 1.0000e-04 - 97ms/epoch - 3ms/step\n",
            "Epoch 15/1800\n",
            "29/29 - 0s - loss: 4.0929 - accuracy: 0.0567 - val_loss: 4.1421 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 93ms/epoch - 3ms/step\n",
            "Epoch 16/1800\n",
            "29/29 - 0s - loss: 4.0660 - accuracy: 0.0658 - val_loss: 4.1315 - val_accuracy: 0.1681 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 17/1800\n",
            "29/29 - 0s - loss: 4.0524 - accuracy: 0.0631 - val_loss: 4.1202 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 18/1800\n",
            "29/29 - 0s - loss: 4.0426 - accuracy: 0.0685 - val_loss: 4.1089 - val_accuracy: 0.1810 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 19/1800\n",
            "29/29 - 0s - loss: 4.0388 - accuracy: 0.0691 - val_loss: 4.0987 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 20/1800\n",
            "29/29 - 0s - loss: 4.0176 - accuracy: 0.0729 - val_loss: 4.0877 - val_accuracy: 0.1983 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 21/1800\n",
            "29/29 - 0s - loss: 3.9874 - accuracy: 0.0718 - val_loss: 4.0760 - val_accuracy: 0.2112 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 22/1800\n",
            "29/29 - 0s - loss: 3.9919 - accuracy: 0.0702 - val_loss: 4.0646 - val_accuracy: 0.2198 - lr: 1.0000e-04 - 98ms/epoch - 3ms/step\n",
            "Epoch 23/1800\n",
            "29/29 - 0s - loss: 3.9533 - accuracy: 0.0874 - val_loss: 4.0529 - val_accuracy: 0.2198 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 24/1800\n",
            "29/29 - 0s - loss: 3.9500 - accuracy: 0.0944 - val_loss: 4.0408 - val_accuracy: 0.2284 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 25/1800\n",
            "29/29 - 0s - loss: 3.9345 - accuracy: 0.1009 - val_loss: 4.0280 - val_accuracy: 0.2328 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 26/1800\n",
            "29/29 - 0s - loss: 3.9065 - accuracy: 0.0988 - val_loss: 4.0144 - val_accuracy: 0.2457 - lr: 1.0000e-04 - 94ms/epoch - 3ms/step\n",
            "Epoch 27/1800\n",
            "29/29 - 0s - loss: 3.9111 - accuracy: 0.0901 - val_loss: 4.0005 - val_accuracy: 0.2543 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 28/1800\n",
            "29/29 - 0s - loss: 3.8883 - accuracy: 0.1063 - val_loss: 3.9884 - val_accuracy: 0.2629 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 29/1800\n",
            "29/29 - 0s - loss: 3.8592 - accuracy: 0.1096 - val_loss: 3.9761 - val_accuracy: 0.2629 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 30/1800\n",
            "29/29 - 0s - loss: 3.8571 - accuracy: 0.1155 - val_loss: 3.9625 - val_accuracy: 0.2845 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 31/1800\n",
            "29/29 - 0s - loss: 3.8265 - accuracy: 0.1203 - val_loss: 3.9486 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 97ms/epoch - 3ms/step\n",
            "Epoch 32/1800\n",
            "29/29 - 0s - loss: 3.8219 - accuracy: 0.1203 - val_loss: 3.9348 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 84ms/epoch - 3ms/step\n",
            "Epoch 33/1800\n",
            "29/29 - 0s - loss: 3.8144 - accuracy: 0.1268 - val_loss: 3.9224 - val_accuracy: 0.2974 - lr: 1.0000e-04 - 99ms/epoch - 3ms/step\n",
            "Epoch 34/1800\n",
            "29/29 - 0s - loss: 3.7661 - accuracy: 0.1290 - val_loss: 3.9087 - val_accuracy: 0.2974 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 35/1800\n",
            "29/29 - 0s - loss: 3.7578 - accuracy: 0.1484 - val_loss: 3.8946 - val_accuracy: 0.2974 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 36/1800\n",
            "29/29 - 0s - loss: 3.7409 - accuracy: 0.1376 - val_loss: 3.8806 - val_accuracy: 0.3017 - lr: 1.0000e-04 - 94ms/epoch - 3ms/step\n",
            "Epoch 37/1800\n",
            "29/29 - 0s - loss: 3.7257 - accuracy: 0.1311 - val_loss: 3.8656 - val_accuracy: 0.3017 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 38/1800\n",
            "29/29 - 0s - loss: 3.6980 - accuracy: 0.1430 - val_loss: 3.8520 - val_accuracy: 0.3060 - lr: 1.0000e-04 - 94ms/epoch - 3ms/step\n",
            "Epoch 39/1800\n",
            "29/29 - 0s - loss: 3.6541 - accuracy: 0.1560 - val_loss: 3.8382 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 40/1800\n",
            "29/29 - 0s - loss: 3.6480 - accuracy: 0.1576 - val_loss: 3.8241 - val_accuracy: 0.3060 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 41/1800\n",
            "29/29 - 0s - loss: 3.6566 - accuracy: 0.1516 - val_loss: 3.8108 - val_accuracy: 0.3147 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 42/1800\n",
            "29/29 - 0s - loss: 3.6541 - accuracy: 0.1565 - val_loss: 3.7965 - val_accuracy: 0.3190 - lr: 1.0000e-04 - 93ms/epoch - 3ms/step\n",
            "Epoch 43/1800\n",
            "29/29 - 0s - loss: 3.6077 - accuracy: 0.1646 - val_loss: 3.7822 - val_accuracy: 0.3233 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 44/1800\n",
            "29/29 - 0s - loss: 3.5901 - accuracy: 0.1673 - val_loss: 3.7687 - val_accuracy: 0.3233 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 45/1800\n",
            "29/29 - 0s - loss: 3.5719 - accuracy: 0.1716 - val_loss: 3.7555 - val_accuracy: 0.3233 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 46/1800\n",
            "29/29 - 0s - loss: 3.5263 - accuracy: 0.1722 - val_loss: 3.7415 - val_accuracy: 0.3319 - lr: 1.0000e-04 - 94ms/epoch - 3ms/step\n",
            "Epoch 47/1800\n",
            "29/29 - 0s - loss: 3.5733 - accuracy: 0.1695 - val_loss: 3.7287 - val_accuracy: 0.3362 - lr: 1.0000e-04 - 94ms/epoch - 3ms/step\n",
            "Epoch 48/1800\n",
            "29/29 - 0s - loss: 3.5723 - accuracy: 0.1641 - val_loss: 3.7159 - val_accuracy: 0.3405 - lr: 1.0000e-04 - 94ms/epoch - 3ms/step\n",
            "Epoch 49/1800\n",
            "29/29 - 0s - loss: 3.5183 - accuracy: 0.1749 - val_loss: 3.7033 - val_accuracy: 0.3362 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 50/1800\n",
            "29/29 - 0s - loss: 3.4884 - accuracy: 0.1975 - val_loss: 3.6904 - val_accuracy: 0.3491 - lr: 1.0000e-04 - 93ms/epoch - 3ms/step\n",
            "Epoch 51/1800\n",
            "29/29 - 0s - loss: 3.5090 - accuracy: 0.1695 - val_loss: 3.6787 - val_accuracy: 0.3491 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 52/1800\n",
            "29/29 - 0s - loss: 3.4489 - accuracy: 0.1824 - val_loss: 3.6657 - val_accuracy: 0.3621 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 53/1800\n",
            "29/29 - 0s - loss: 3.4626 - accuracy: 0.1943 - val_loss: 3.6533 - val_accuracy: 0.3578 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 54/1800\n",
            "29/29 - 0s - loss: 3.4393 - accuracy: 0.1964 - val_loss: 3.6400 - val_accuracy: 0.3621 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 55/1800\n",
            "29/29 - 0s - loss: 3.4235 - accuracy: 0.2056 - val_loss: 3.6276 - val_accuracy: 0.3664 - lr: 1.0000e-04 - 93ms/epoch - 3ms/step\n",
            "Epoch 56/1800\n",
            "29/29 - 0s - loss: 3.3939 - accuracy: 0.2062 - val_loss: 3.6151 - val_accuracy: 0.3750 - lr: 1.0000e-04 - 94ms/epoch - 3ms/step\n",
            "Epoch 57/1800\n",
            "29/29 - 0s - loss: 3.3858 - accuracy: 0.2078 - val_loss: 3.6035 - val_accuracy: 0.3793 - lr: 1.0000e-04 - 98ms/epoch - 3ms/step\n",
            "Epoch 58/1800\n",
            "29/29 - 0s - loss: 3.3719 - accuracy: 0.2018 - val_loss: 3.5907 - val_accuracy: 0.3793 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 59/1800\n",
            "29/29 - 0s - loss: 3.3666 - accuracy: 0.2056 - val_loss: 3.5788 - val_accuracy: 0.3793 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 60/1800\n",
            "29/29 - 0s - loss: 3.3486 - accuracy: 0.2137 - val_loss: 3.5667 - val_accuracy: 0.3836 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 61/1800\n",
            "29/29 - 0s - loss: 3.3186 - accuracy: 0.2029 - val_loss: 3.5554 - val_accuracy: 0.3836 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 62/1800\n",
            "29/29 - 0s - loss: 3.3257 - accuracy: 0.2153 - val_loss: 3.5439 - val_accuracy: 0.3836 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 63/1800\n",
            "29/29 - 0s - loss: 3.3299 - accuracy: 0.2240 - val_loss: 3.5325 - val_accuracy: 0.3836 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 64/1800\n",
            "29/29 - 0s - loss: 3.2702 - accuracy: 0.2218 - val_loss: 3.5204 - val_accuracy: 0.3836 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 65/1800\n",
            "29/29 - 0s - loss: 3.2784 - accuracy: 0.2234 - val_loss: 3.5098 - val_accuracy: 0.3836 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 66/1800\n",
            "29/29 - 0s - loss: 3.2768 - accuracy: 0.2002 - val_loss: 3.4990 - val_accuracy: 0.3836 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 67/1800\n",
            "29/29 - 0s - loss: 3.2348 - accuracy: 0.2385 - val_loss: 3.4873 - val_accuracy: 0.3836 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 68/1800\n",
            "29/29 - 0s - loss: 3.2226 - accuracy: 0.2337 - val_loss: 3.4760 - val_accuracy: 0.3879 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 69/1800\n",
            "29/29 - 0s - loss: 3.1898 - accuracy: 0.2380 - val_loss: 3.4633 - val_accuracy: 0.3966 - lr: 1.0000e-04 - 98ms/epoch - 3ms/step\n",
            "Epoch 70/1800\n",
            "29/29 - 0s - loss: 3.1993 - accuracy: 0.2196 - val_loss: 3.4519 - val_accuracy: 0.3966 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 71/1800\n",
            "29/29 - 0s - loss: 3.1898 - accuracy: 0.2294 - val_loss: 3.4414 - val_accuracy: 0.3966 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 72/1800\n",
            "29/29 - 0s - loss: 3.1920 - accuracy: 0.2402 - val_loss: 3.4307 - val_accuracy: 0.4009 - lr: 1.0000e-04 - 94ms/epoch - 3ms/step\n",
            "Epoch 73/1800\n",
            "29/29 - 0s - loss: 3.2062 - accuracy: 0.2315 - val_loss: 3.4224 - val_accuracy: 0.4009 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 74/1800\n",
            "29/29 - 0s - loss: 3.1663 - accuracy: 0.2380 - val_loss: 3.4116 - val_accuracy: 0.3966 - lr: 1.0000e-04 - 77ms/epoch - 3ms/step\n",
            "Epoch 75/1800\n",
            "29/29 - 0s - loss: 3.1372 - accuracy: 0.2412 - val_loss: 3.4003 - val_accuracy: 0.3966 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 76/1800\n",
            "29/29 - 0s - loss: 3.1125 - accuracy: 0.2585 - val_loss: 3.3907 - val_accuracy: 0.4095 - lr: 1.0000e-04 - 98ms/epoch - 3ms/step\n",
            "Epoch 77/1800\n",
            "29/29 - 0s - loss: 3.1440 - accuracy: 0.2272 - val_loss: 3.3821 - val_accuracy: 0.4052 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 78/1800\n",
            "29/29 - 0s - loss: 3.1001 - accuracy: 0.2526 - val_loss: 3.3724 - val_accuracy: 0.4052 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 79/1800\n",
            "29/29 - 0s - loss: 3.0984 - accuracy: 0.2461 - val_loss: 3.3623 - val_accuracy: 0.4009 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 80/1800\n",
            "29/29 - 0s - loss: 3.0726 - accuracy: 0.2504 - val_loss: 3.3510 - val_accuracy: 0.4052 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 81/1800\n",
            "29/29 - 0s - loss: 3.0628 - accuracy: 0.2601 - val_loss: 3.3419 - val_accuracy: 0.4009 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 82/1800\n",
            "29/29 - 0s - loss: 3.0787 - accuracy: 0.2499 - val_loss: 3.3319 - val_accuracy: 0.4052 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 83/1800\n",
            "29/29 - 0s - loss: 3.0065 - accuracy: 0.2612 - val_loss: 3.3216 - val_accuracy: 0.4052 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 84/1800\n",
            "29/29 - 0s - loss: 3.0216 - accuracy: 0.2758 - val_loss: 3.3129 - val_accuracy: 0.4095 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 85/1800\n",
            "29/29 - 0s - loss: 3.0685 - accuracy: 0.2574 - val_loss: 3.3051 - val_accuracy: 0.4138 - lr: 1.0000e-04 - 94ms/epoch - 3ms/step\n",
            "Epoch 86/1800\n",
            "29/29 - 0s - loss: 3.0390 - accuracy: 0.2499 - val_loss: 3.2969 - val_accuracy: 0.4138 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 87/1800\n",
            "29/29 - 0s - loss: 3.0040 - accuracy: 0.2585 - val_loss: 3.2887 - val_accuracy: 0.4095 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 88/1800\n",
            "29/29 - 0s - loss: 3.0047 - accuracy: 0.2693 - val_loss: 3.2806 - val_accuracy: 0.4224 - lr: 1.0000e-04 - 97ms/epoch - 3ms/step\n",
            "Epoch 89/1800\n",
            "29/29 - 0s - loss: 2.9894 - accuracy: 0.2709 - val_loss: 3.2709 - val_accuracy: 0.4181 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 90/1800\n",
            "29/29 - 0s - loss: 2.9698 - accuracy: 0.2704 - val_loss: 3.2627 - val_accuracy: 0.4095 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 91/1800\n",
            "29/29 - 0s - loss: 2.9893 - accuracy: 0.2644 - val_loss: 3.2539 - val_accuracy: 0.4224 - lr: 1.0000e-04 - 77ms/epoch - 3ms/step\n",
            "Epoch 92/1800\n",
            "29/29 - 0s - loss: 2.9560 - accuracy: 0.2742 - val_loss: 3.2443 - val_accuracy: 0.4267 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 93/1800\n",
            "29/29 - 0s - loss: 2.9271 - accuracy: 0.2742 - val_loss: 3.2368 - val_accuracy: 0.4353 - lr: 1.0000e-04 - 97ms/epoch - 3ms/step\n",
            "Epoch 94/1800\n",
            "29/29 - 0s - loss: 2.9505 - accuracy: 0.2806 - val_loss: 3.2294 - val_accuracy: 0.4267 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 95/1800\n",
            "29/29 - 0s - loss: 2.9228 - accuracy: 0.2731 - val_loss: 3.2205 - val_accuracy: 0.4353 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 96/1800\n",
            "29/29 - 0s - loss: 2.8772 - accuracy: 0.2806 - val_loss: 3.2118 - val_accuracy: 0.4310 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 97/1800\n",
            "29/29 - 0s - loss: 2.9143 - accuracy: 0.2639 - val_loss: 3.2034 - val_accuracy: 0.4310 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 98/1800\n",
            "29/29 - 0s - loss: 2.9262 - accuracy: 0.2704 - val_loss: 3.1954 - val_accuracy: 0.4310 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 99/1800\n",
            "29/29 - 0s - loss: 2.8901 - accuracy: 0.2828 - val_loss: 3.1872 - val_accuracy: 0.4310 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 100/1800\n",
            "29/29 - 0s - loss: 2.8510 - accuracy: 0.2876 - val_loss: 3.1797 - val_accuracy: 0.4267 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 101/1800\n",
            "29/29 - 0s - loss: 2.8705 - accuracy: 0.2920 - val_loss: 3.1721 - val_accuracy: 0.4310 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 102/1800\n",
            "29/29 - 0s - loss: 2.8621 - accuracy: 0.2736 - val_loss: 3.1652 - val_accuracy: 0.4310 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 103/1800\n",
            "29/29 - 0s - loss: 2.8891 - accuracy: 0.2833 - val_loss: 3.1583 - val_accuracy: 0.4310 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 104/1800\n",
            "29/29 - 0s - loss: 2.8633 - accuracy: 0.2774 - val_loss: 3.1522 - val_accuracy: 0.4310 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 105/1800\n",
            "29/29 - 0s - loss: 2.8250 - accuracy: 0.2984 - val_loss: 3.1442 - val_accuracy: 0.4353 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 106/1800\n",
            "29/29 - 0s - loss: 2.8348 - accuracy: 0.2871 - val_loss: 3.1359 - val_accuracy: 0.4353 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 107/1800\n",
            "29/29 - 0s - loss: 2.8237 - accuracy: 0.2882 - val_loss: 3.1291 - val_accuracy: 0.4353 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 108/1800\n",
            "29/29 - 0s - loss: 2.8103 - accuracy: 0.2957 - val_loss: 3.1209 - val_accuracy: 0.4353 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 109/1800\n",
            "29/29 - 0s - loss: 2.7651 - accuracy: 0.2947 - val_loss: 3.1130 - val_accuracy: 0.4397 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 110/1800\n",
            "29/29 - 0s - loss: 2.7795 - accuracy: 0.3022 - val_loss: 3.1062 - val_accuracy: 0.4353 - lr: 1.0000e-04 - 85ms/epoch - 3ms/step\n",
            "Epoch 111/1800\n",
            "29/29 - 0s - loss: 2.7666 - accuracy: 0.3006 - val_loss: 3.0997 - val_accuracy: 0.4483 - lr: 1.0000e-04 - 100ms/epoch - 3ms/step\n",
            "Epoch 112/1800\n",
            "29/29 - 0s - loss: 2.7625 - accuracy: 0.3065 - val_loss: 3.0917 - val_accuracy: 0.4440 - lr: 1.0000e-04 - 84ms/epoch - 3ms/step\n",
            "Epoch 113/1800\n",
            "29/29 - 0s - loss: 2.7608 - accuracy: 0.2930 - val_loss: 3.0856 - val_accuracy: 0.4397 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 114/1800\n",
            "29/29 - 0s - loss: 2.7662 - accuracy: 0.2925 - val_loss: 3.0789 - val_accuracy: 0.4483 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 115/1800\n",
            "29/29 - 0s - loss: 2.7386 - accuracy: 0.3055 - val_loss: 3.0709 - val_accuracy: 0.4483 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 116/1800\n",
            "29/29 - 0s - loss: 2.7529 - accuracy: 0.3001 - val_loss: 3.0651 - val_accuracy: 0.4483 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 117/1800\n",
            "29/29 - 0s - loss: 2.7275 - accuracy: 0.2936 - val_loss: 3.0591 - val_accuracy: 0.4483 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 118/1800\n",
            "29/29 - 0s - loss: 2.7074 - accuracy: 0.3038 - val_loss: 3.0507 - val_accuracy: 0.4483 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 119/1800\n",
            "29/29 - 0s - loss: 2.7233 - accuracy: 0.3179 - val_loss: 3.0451 - val_accuracy: 0.4569 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 120/1800\n",
            "29/29 - 0s - loss: 2.7171 - accuracy: 0.3168 - val_loss: 3.0394 - val_accuracy: 0.4526 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 121/1800\n",
            "29/29 - 0s - loss: 2.7126 - accuracy: 0.3065 - val_loss: 3.0335 - val_accuracy: 0.4569 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 122/1800\n",
            "29/29 - 0s - loss: 2.6837 - accuracy: 0.3044 - val_loss: 3.0261 - val_accuracy: 0.4569 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 123/1800\n",
            "29/29 - 0s - loss: 2.7007 - accuracy: 0.3028 - val_loss: 3.0211 - val_accuracy: 0.4569 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 124/1800\n",
            "29/29 - 0s - loss: 2.6267 - accuracy: 0.3189 - val_loss: 3.0131 - val_accuracy: 0.4569 - lr: 1.0000e-04 - 86ms/epoch - 3ms/step\n",
            "Epoch 125/1800\n",
            "29/29 - 0s - loss: 2.6483 - accuracy: 0.3092 - val_loss: 3.0065 - val_accuracy: 0.4569 - lr: 1.0000e-04 - 84ms/epoch - 3ms/step\n",
            "Epoch 126/1800\n",
            "29/29 - 0s - loss: 2.6724 - accuracy: 0.3103 - val_loss: 3.0008 - val_accuracy: 0.4569 - lr: 1.0000e-04 - 84ms/epoch - 3ms/step\n",
            "Epoch 127/1800\n",
            "29/29 - 0s - loss: 2.6705 - accuracy: 0.3135 - val_loss: 2.9949 - val_accuracy: 0.4569 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 128/1800\n",
            "29/29 - 0s - loss: 2.6385 - accuracy: 0.3195 - val_loss: 2.9885 - val_accuracy: 0.4569 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 129/1800\n",
            "29/29 - 0s - loss: 2.5863 - accuracy: 0.3297 - val_loss: 2.9818 - val_accuracy: 0.4612 - lr: 1.0000e-04 - 98ms/epoch - 3ms/step\n",
            "Epoch 130/1800\n",
            "29/29 - 0s - loss: 2.6275 - accuracy: 0.3222 - val_loss: 2.9761 - val_accuracy: 0.4612 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 131/1800\n",
            "29/29 - 0s - loss: 2.6174 - accuracy: 0.3287 - val_loss: 2.9700 - val_accuracy: 0.4612 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 132/1800\n",
            "29/29 - 0s - loss: 2.5848 - accuracy: 0.3287 - val_loss: 2.9628 - val_accuracy: 0.4612 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 133/1800\n",
            "29/29 - 0s - loss: 2.6278 - accuracy: 0.3168 - val_loss: 2.9578 - val_accuracy: 0.4612 - lr: 1.0000e-04 - 89ms/epoch - 3ms/step\n",
            "Epoch 134/1800\n",
            "29/29 - 0s - loss: 2.5946 - accuracy: 0.3260 - val_loss: 2.9519 - val_accuracy: 0.4569 - lr: 1.0000e-04 - 86ms/epoch - 3ms/step\n",
            "Epoch 135/1800\n",
            "29/29 - 0s - loss: 2.5671 - accuracy: 0.3297 - val_loss: 2.9459 - val_accuracy: 0.4655 - lr: 1.0000e-04 - 104ms/epoch - 4ms/step\n",
            "Epoch 136/1800\n",
            "29/29 - 0s - loss: 2.5446 - accuracy: 0.3292 - val_loss: 2.9404 - val_accuracy: 0.4655 - lr: 1.0000e-04 - 85ms/epoch - 3ms/step\n",
            "Epoch 137/1800\n",
            "29/29 - 0s - loss: 2.5495 - accuracy: 0.3238 - val_loss: 2.9358 - val_accuracy: 0.4698 - lr: 1.0000e-04 - 107ms/epoch - 4ms/step\n",
            "Epoch 138/1800\n",
            "29/29 - 0s - loss: 2.5744 - accuracy: 0.3216 - val_loss: 2.9299 - val_accuracy: 0.4698 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 139/1800\n",
            "29/29 - 0s - loss: 2.5346 - accuracy: 0.3297 - val_loss: 2.9222 - val_accuracy: 0.4698 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 140/1800\n",
            "29/29 - 0s - loss: 2.5257 - accuracy: 0.3368 - val_loss: 2.9154 - val_accuracy: 0.4612 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 141/1800\n",
            "29/29 - 0s - loss: 2.5235 - accuracy: 0.3405 - val_loss: 2.9098 - val_accuracy: 0.4655 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 142/1800\n",
            "29/29 - 0s - loss: 2.5420 - accuracy: 0.3265 - val_loss: 2.9051 - val_accuracy: 0.4655 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 143/1800\n",
            "29/29 - 0s - loss: 2.4804 - accuracy: 0.3394 - val_loss: 2.8992 - val_accuracy: 0.4828 - lr: 1.0000e-04 - 97ms/epoch - 3ms/step\n",
            "Epoch 144/1800\n",
            "29/29 - 0s - loss: 2.5581 - accuracy: 0.3157 - val_loss: 2.8940 - val_accuracy: 0.4784 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 145/1800\n",
            "29/29 - 0s - loss: 2.4832 - accuracy: 0.3427 - val_loss: 2.8887 - val_accuracy: 0.4784 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 146/1800\n",
            "29/29 - 0s - loss: 2.4885 - accuracy: 0.3432 - val_loss: 2.8825 - val_accuracy: 0.4784 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 147/1800\n",
            "29/29 - 0s - loss: 2.4870 - accuracy: 0.3502 - val_loss: 2.8781 - val_accuracy: 0.4828 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 148/1800\n",
            "29/29 - 0s - loss: 2.4546 - accuracy: 0.3535 - val_loss: 2.8725 - val_accuracy: 0.4828 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 149/1800\n",
            "29/29 - 0s - loss: 2.4088 - accuracy: 0.3562 - val_loss: 2.8667 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 150/1800\n",
            "29/29 - 0s - loss: 2.4619 - accuracy: 0.3502 - val_loss: 2.8621 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 151/1800\n",
            "29/29 - 0s - loss: 2.4464 - accuracy: 0.3448 - val_loss: 2.8573 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 152/1800\n",
            "29/29 - 0s - loss: 2.4781 - accuracy: 0.3378 - val_loss: 2.8527 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 153/1800\n",
            "29/29 - 0s - loss: 2.4326 - accuracy: 0.3454 - val_loss: 2.8478 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 154/1800\n",
            "29/29 - 0s - loss: 2.4039 - accuracy: 0.3529 - val_loss: 2.8432 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 155/1800\n",
            "29/29 - 0s - loss: 2.4165 - accuracy: 0.3475 - val_loss: 2.8376 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 156/1800\n",
            "29/29 - 0s - loss: 2.4570 - accuracy: 0.3508 - val_loss: 2.8317 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 157/1800\n",
            "29/29 - 0s - loss: 2.4421 - accuracy: 0.3432 - val_loss: 2.8269 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 158/1800\n",
            "29/29 - 0s - loss: 2.4198 - accuracy: 0.3405 - val_loss: 2.8217 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 159/1800\n",
            "29/29 - 0s - loss: 2.4050 - accuracy: 0.3475 - val_loss: 2.8168 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 160/1800\n",
            "29/29 - 0s - loss: 2.3859 - accuracy: 0.3513 - val_loss: 2.8120 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 161/1800\n",
            "29/29 - 0s - loss: 2.4159 - accuracy: 0.3492 - val_loss: 2.8072 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 162/1800\n",
            "29/29 - 0s - loss: 2.3649 - accuracy: 0.3540 - val_loss: 2.8025 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 163/1800\n",
            "29/29 - 0s - loss: 2.3872 - accuracy: 0.3546 - val_loss: 2.7981 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 164/1800\n",
            "29/29 - 0s - loss: 2.3569 - accuracy: 0.3578 - val_loss: 2.7937 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 165/1800\n",
            "29/29 - 0s - loss: 2.3577 - accuracy: 0.3594 - val_loss: 2.7888 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 97ms/epoch - 3ms/step\n",
            "Epoch 166/1800\n",
            "29/29 - 0s - loss: 2.3681 - accuracy: 0.3627 - val_loss: 2.7837 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 167/1800\n",
            "29/29 - 0s - loss: 2.3420 - accuracy: 0.3594 - val_loss: 2.7786 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 168/1800\n",
            "29/29 - 0s - loss: 2.3244 - accuracy: 0.3659 - val_loss: 2.7753 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 169/1800\n",
            "29/29 - 0s - loss: 2.3312 - accuracy: 0.3675 - val_loss: 2.7711 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 84ms/epoch - 3ms/step\n",
            "Epoch 170/1800\n",
            "29/29 - 0s - loss: 2.3389 - accuracy: 0.3627 - val_loss: 2.7663 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 171/1800\n",
            "29/29 - 0s - loss: 2.3123 - accuracy: 0.3627 - val_loss: 2.7623 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 172/1800\n",
            "29/29 - 0s - loss: 2.3523 - accuracy: 0.3686 - val_loss: 2.7586 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 173/1800\n",
            "29/29 - 0s - loss: 2.3582 - accuracy: 0.3659 - val_loss: 2.7560 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 174/1800\n",
            "29/29 - 0s - loss: 2.2979 - accuracy: 0.3837 - val_loss: 2.7510 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 175/1800\n",
            "29/29 - 0s - loss: 2.2720 - accuracy: 0.3837 - val_loss: 2.7456 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 176/1800\n",
            "29/29 - 0s - loss: 2.2590 - accuracy: 0.3794 - val_loss: 2.7398 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 177/1800\n",
            "29/29 - 0s - loss: 2.2763 - accuracy: 0.3886 - val_loss: 2.7351 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 178/1800\n",
            "29/29 - 0s - loss: 2.3193 - accuracy: 0.3562 - val_loss: 2.7321 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 179/1800\n",
            "29/29 - 0s - loss: 2.2337 - accuracy: 0.3842 - val_loss: 2.7266 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 180/1800\n",
            "29/29 - 0s - loss: 2.2587 - accuracy: 0.3805 - val_loss: 2.7223 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 181/1800\n",
            "29/29 - 0s - loss: 2.3148 - accuracy: 0.3497 - val_loss: 2.7176 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 182/1800\n",
            "29/29 - 0s - loss: 2.2882 - accuracy: 0.3729 - val_loss: 2.7119 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 183/1800\n",
            "29/29 - 0s - loss: 2.2431 - accuracy: 0.3751 - val_loss: 2.7073 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 184/1800\n",
            "29/29 - 0s - loss: 2.2421 - accuracy: 0.3783 - val_loss: 2.7041 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 185/1800\n",
            "29/29 - 0s - loss: 2.2529 - accuracy: 0.3729 - val_loss: 2.7002 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 186/1800\n",
            "29/29 - 0s - loss: 2.2209 - accuracy: 0.3783 - val_loss: 2.6972 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 187/1800\n",
            "29/29 - 0s - loss: 2.2510 - accuracy: 0.3708 - val_loss: 2.6929 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 188/1800\n",
            "29/29 - 0s - loss: 2.2164 - accuracy: 0.3859 - val_loss: 2.6886 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 189/1800\n",
            "29/29 - 0s - loss: 2.2424 - accuracy: 0.3772 - val_loss: 2.6843 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 190/1800\n",
            "29/29 - 0s - loss: 2.2002 - accuracy: 0.3929 - val_loss: 2.6809 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 191/1800\n",
            "29/29 - 0s - loss: 2.2151 - accuracy: 0.3869 - val_loss: 2.6765 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 192/1800\n",
            "29/29 - 0s - loss: 2.2130 - accuracy: 0.3826 - val_loss: 2.6720 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 193/1800\n",
            "29/29 - 0s - loss: 2.1771 - accuracy: 0.3869 - val_loss: 2.6684 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 194/1800\n",
            "29/29 - 0s - loss: 2.1790 - accuracy: 0.3972 - val_loss: 2.6641 - val_accuracy: 0.4914 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 195/1800\n",
            "29/29 - 0s - loss: 2.2044 - accuracy: 0.3923 - val_loss: 2.6615 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 196/1800\n",
            "29/29 - 0s - loss: 2.1979 - accuracy: 0.3821 - val_loss: 2.6587 - val_accuracy: 0.4871 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 197/1800\n",
            "29/29 - 0s - loss: 2.1669 - accuracy: 0.4107 - val_loss: 2.6540 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 198/1800\n",
            "29/29 - 0s - loss: 2.2498 - accuracy: 0.3632 - val_loss: 2.6503 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 199/1800\n",
            "29/29 - 0s - loss: 2.1407 - accuracy: 0.4069 - val_loss: 2.6459 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 200/1800\n",
            "29/29 - 0s - loss: 2.1419 - accuracy: 0.3972 - val_loss: 2.6407 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 201/1800\n",
            "29/29 - 0s - loss: 2.1284 - accuracy: 0.3967 - val_loss: 2.6377 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 202/1800\n",
            "29/29 - 0s - loss: 2.1883 - accuracy: 0.3961 - val_loss: 2.6334 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 203/1800\n",
            "29/29 - 0s - loss: 2.1511 - accuracy: 0.3913 - val_loss: 2.6299 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 204/1800\n",
            "29/29 - 0s - loss: 2.0938 - accuracy: 0.4042 - val_loss: 2.6256 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 205/1800\n",
            "29/29 - 0s - loss: 2.1794 - accuracy: 0.3837 - val_loss: 2.6225 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 206/1800\n",
            "29/29 - 0s - loss: 2.1486 - accuracy: 0.3961 - val_loss: 2.6189 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 207/1800\n",
            "29/29 - 0s - loss: 2.1434 - accuracy: 0.3994 - val_loss: 2.6155 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 97ms/epoch - 3ms/step\n",
            "Epoch 208/1800\n",
            "29/29 - 0s - loss: 2.1216 - accuracy: 0.4026 - val_loss: 2.6132 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 209/1800\n",
            "29/29 - 0s - loss: 2.0974 - accuracy: 0.4085 - val_loss: 2.6088 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 210/1800\n",
            "29/29 - 0s - loss: 2.0938 - accuracy: 0.4031 - val_loss: 2.6055 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 97ms/epoch - 3ms/step\n",
            "Epoch 211/1800\n",
            "29/29 - 0s - loss: 2.1480 - accuracy: 0.3994 - val_loss: 2.6010 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 212/1800\n",
            "29/29 - 0s - loss: 2.1127 - accuracy: 0.3967 - val_loss: 2.5980 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 213/1800\n",
            "29/29 - 0s - loss: 2.1224 - accuracy: 0.3950 - val_loss: 2.5945 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 214/1800\n",
            "29/29 - 0s - loss: 2.0945 - accuracy: 0.3999 - val_loss: 2.5906 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 215/1800\n",
            "29/29 - 0s - loss: 2.0752 - accuracy: 0.4150 - val_loss: 2.5867 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 216/1800\n",
            "29/29 - 0s - loss: 2.0835 - accuracy: 0.3950 - val_loss: 2.5854 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 217/1800\n",
            "29/29 - 0s - loss: 2.0688 - accuracy: 0.4010 - val_loss: 2.5817 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 218/1800\n",
            "29/29 - 0s - loss: 2.0811 - accuracy: 0.3988 - val_loss: 2.5793 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 219/1800\n",
            "29/29 - 0s - loss: 2.0726 - accuracy: 0.4053 - val_loss: 2.5763 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 220/1800\n",
            "29/29 - 0s - loss: 2.0299 - accuracy: 0.4209 - val_loss: 2.5729 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 221/1800\n",
            "29/29 - 0s - loss: 2.0563 - accuracy: 0.4074 - val_loss: 2.5691 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 222/1800\n",
            "29/29 - 0s - loss: 2.0481 - accuracy: 0.4253 - val_loss: 2.5656 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 223/1800\n",
            "29/29 - 0s - loss: 2.0048 - accuracy: 0.4096 - val_loss: 2.5619 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 224/1800\n",
            "29/29 - 0s - loss: 2.0972 - accuracy: 0.3999 - val_loss: 2.5582 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 225/1800\n",
            "29/29 - 0s - loss: 2.0315 - accuracy: 0.4199 - val_loss: 2.5560 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 95ms/epoch - 3ms/step\n",
            "Epoch 226/1800\n",
            "29/29 - 0s - loss: 1.9937 - accuracy: 0.4290 - val_loss: 2.5520 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 227/1800\n",
            "29/29 - 0s - loss: 2.0524 - accuracy: 0.4128 - val_loss: 2.5495 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 228/1800\n",
            "29/29 - 0s - loss: 1.9844 - accuracy: 0.4166 - val_loss: 2.5468 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 229/1800\n",
            "29/29 - 0s - loss: 2.0132 - accuracy: 0.4209 - val_loss: 2.5441 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 230/1800\n",
            "29/29 - 0s - loss: 2.0301 - accuracy: 0.4172 - val_loss: 2.5414 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 231/1800\n",
            "29/29 - 0s - loss: 2.0079 - accuracy: 0.4220 - val_loss: 2.5382 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 232/1800\n",
            "29/29 - 0s - loss: 2.0007 - accuracy: 0.4193 - val_loss: 2.5349 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 233/1800\n",
            "29/29 - 0s - loss: 2.0308 - accuracy: 0.4101 - val_loss: 2.5322 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 234/1800\n",
            "29/29 - 0s - loss: 2.0026 - accuracy: 0.4247 - val_loss: 2.5299 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 235/1800\n",
            "29/29 - 0s - loss: 2.0081 - accuracy: 0.4199 - val_loss: 2.5264 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 236/1800\n",
            "29/29 - 0s - loss: 1.9634 - accuracy: 0.4323 - val_loss: 2.5231 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 237/1800\n",
            "29/29 - 0s - loss: 2.0069 - accuracy: 0.4263 - val_loss: 2.5196 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 238/1800\n",
            "29/29 - 0s - loss: 1.9424 - accuracy: 0.4344 - val_loss: 2.5175 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 239/1800\n",
            "29/29 - 0s - loss: 1.9899 - accuracy: 0.4199 - val_loss: 2.5149 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 240/1800\n",
            "29/29 - 0s - loss: 1.9174 - accuracy: 0.4420 - val_loss: 2.5108 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 241/1800\n",
            "29/29 - 0s - loss: 1.9535 - accuracy: 0.4258 - val_loss: 2.5075 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 242/1800\n",
            "29/29 - 0s - loss: 1.9539 - accuracy: 0.4182 - val_loss: 2.5049 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 243/1800\n",
            "29/29 - 0s - loss: 1.9607 - accuracy: 0.4307 - val_loss: 2.5021 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 244/1800\n",
            "29/29 - 0s - loss: 1.9770 - accuracy: 0.4301 - val_loss: 2.5005 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 245/1800\n",
            "29/29 - 0s - loss: 1.9457 - accuracy: 0.4339 - val_loss: 2.4977 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 86ms/epoch - 3ms/step\n",
            "Epoch 246/1800\n",
            "29/29 - 0s - loss: 1.9427 - accuracy: 0.4269 - val_loss: 2.4951 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 247/1800\n",
            "29/29 - 0s - loss: 1.8752 - accuracy: 0.4355 - val_loss: 2.4914 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 248/1800\n",
            "29/29 - 0s - loss: 1.9290 - accuracy: 0.4285 - val_loss: 2.4893 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 249/1800\n",
            "29/29 - 0s - loss: 1.9259 - accuracy: 0.4398 - val_loss: 2.4865 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 250/1800\n",
            "29/29 - 0s - loss: 1.9930 - accuracy: 0.4177 - val_loss: 2.4844 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 251/1800\n",
            "29/29 - 0s - loss: 1.9540 - accuracy: 0.4269 - val_loss: 2.4827 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 252/1800\n",
            "29/29 - 0s - loss: 1.9380 - accuracy: 0.4296 - val_loss: 2.4797 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 253/1800\n",
            "29/29 - 0s - loss: 1.9387 - accuracy: 0.4366 - val_loss: 2.4782 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 254/1800\n",
            "29/29 - 0s - loss: 1.9123 - accuracy: 0.4404 - val_loss: 2.4759 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 255/1800\n",
            "29/29 - 0s - loss: 1.8931 - accuracy: 0.4371 - val_loss: 2.4734 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 256/1800\n",
            "29/29 - 0s - loss: 1.9257 - accuracy: 0.4247 - val_loss: 2.4706 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 96ms/epoch - 3ms/step\n",
            "Epoch 257/1800\n",
            "29/29 - 0s - loss: 1.8993 - accuracy: 0.4199 - val_loss: 2.4690 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 258/1800\n",
            "29/29 - 0s - loss: 1.9362 - accuracy: 0.4280 - val_loss: 2.4658 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 259/1800\n",
            "29/29 - 0s - loss: 1.9296 - accuracy: 0.4226 - val_loss: 2.4646 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 260/1800\n",
            "29/29 - 0s - loss: 1.8582 - accuracy: 0.4555 - val_loss: 2.4617 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 261/1800\n",
            "29/29 - 0s - loss: 1.9181 - accuracy: 0.4458 - val_loss: 2.4592 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 262/1800\n",
            "29/29 - 0s - loss: 1.8895 - accuracy: 0.4420 - val_loss: 2.4575 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 263/1800\n",
            "29/29 - 0s - loss: 1.9092 - accuracy: 0.4258 - val_loss: 2.4554 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 264/1800\n",
            "29/29 - 0s - loss: 1.8820 - accuracy: 0.4355 - val_loss: 2.4531 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 265/1800\n",
            "29/29 - 0s - loss: 1.8575 - accuracy: 0.4344 - val_loss: 2.4496 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 266/1800\n",
            "29/29 - 0s - loss: 1.8676 - accuracy: 0.4344 - val_loss: 2.4472 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 267/1800\n",
            "29/29 - 0s - loss: 1.8961 - accuracy: 0.4387 - val_loss: 2.4446 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 268/1800\n",
            "29/29 - 0s - loss: 1.8662 - accuracy: 0.4263 - val_loss: 2.4432 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 269/1800\n",
            "29/29 - 0s - loss: 1.8475 - accuracy: 0.4468 - val_loss: 2.4399 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 85ms/epoch - 3ms/step\n",
            "Epoch 270/1800\n",
            "29/29 - 0s - loss: 1.8363 - accuracy: 0.4431 - val_loss: 2.4372 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 271/1800\n",
            "29/29 - 0s - loss: 1.8453 - accuracy: 0.4398 - val_loss: 2.4344 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 272/1800\n",
            "29/29 - 0s - loss: 1.8153 - accuracy: 0.4603 - val_loss: 2.4333 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 273/1800\n",
            "29/29 - 0s - loss: 1.8340 - accuracy: 0.4360 - val_loss: 2.4305 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 84ms/epoch - 3ms/step\n",
            "Epoch 274/1800\n",
            "29/29 - 0s - loss: 1.8608 - accuracy: 0.4366 - val_loss: 2.4293 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 275/1800\n",
            "29/29 - 0s - loss: 1.8361 - accuracy: 0.4312 - val_loss: 2.4271 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 276/1800\n",
            "29/29 - 0s - loss: 1.8590 - accuracy: 0.4344 - val_loss: 2.4254 - val_accuracy: 0.5216 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 277/1800\n",
            "29/29 - 0s - loss: 1.7939 - accuracy: 0.4587 - val_loss: 2.4236 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 278/1800\n",
            "29/29 - 0s - loss: 1.7866 - accuracy: 0.4614 - val_loss: 2.4212 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 279/1800\n",
            "29/29 - 0s - loss: 1.8002 - accuracy: 0.4555 - val_loss: 2.4201 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 280/1800\n",
            "29/29 - 0s - loss: 1.8717 - accuracy: 0.4441 - val_loss: 2.4180 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 281/1800\n",
            "29/29 - 0s - loss: 1.8327 - accuracy: 0.4382 - val_loss: 2.4170 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 282/1800\n",
            "29/29 - 0s - loss: 1.7598 - accuracy: 0.4603 - val_loss: 2.4125 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 283/1800\n",
            "29/29 - 0s - loss: 1.8642 - accuracy: 0.4387 - val_loss: 2.4104 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 284/1800\n",
            "29/29 - 0s - loss: 1.7963 - accuracy: 0.4495 - val_loss: 2.4090 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 285/1800\n",
            "29/29 - 0s - loss: 1.8019 - accuracy: 0.4479 - val_loss: 2.4067 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 286/1800\n",
            "29/29 - 0s - loss: 1.7926 - accuracy: 0.4512 - val_loss: 2.4036 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 287/1800\n",
            "29/29 - 0s - loss: 1.7517 - accuracy: 0.4630 - val_loss: 2.4006 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 288/1800\n",
            "29/29 - 0s - loss: 1.7636 - accuracy: 0.4647 - val_loss: 2.3995 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 289/1800\n",
            "29/29 - 0s - loss: 1.8070 - accuracy: 0.4566 - val_loss: 2.3990 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 290/1800\n",
            "29/29 - 0s - loss: 1.7832 - accuracy: 0.4463 - val_loss: 2.3973 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 291/1800\n",
            "29/29 - 0s - loss: 1.7353 - accuracy: 0.4711 - val_loss: 2.3954 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 292/1800\n",
            "29/29 - 0s - loss: 1.7908 - accuracy: 0.4501 - val_loss: 2.3938 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 293/1800\n",
            "29/29 - 0s - loss: 1.7718 - accuracy: 0.4593 - val_loss: 2.3918 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 294/1800\n",
            "29/29 - 0s - loss: 1.7766 - accuracy: 0.4620 - val_loss: 2.3879 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 295/1800\n",
            "29/29 - 0s - loss: 1.7449 - accuracy: 0.4657 - val_loss: 2.3861 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 296/1800\n",
            "29/29 - 0s - loss: 1.7543 - accuracy: 0.4630 - val_loss: 2.3841 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 297/1800\n",
            "29/29 - 0s - loss: 1.7426 - accuracy: 0.4771 - val_loss: 2.3826 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 298/1800\n",
            "29/29 - 0s - loss: 1.7106 - accuracy: 0.4668 - val_loss: 2.3814 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 299/1800\n",
            "29/29 - 0s - loss: 1.7468 - accuracy: 0.4690 - val_loss: 2.3794 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 300/1800\n",
            "29/29 - 0s - loss: 1.7466 - accuracy: 0.4598 - val_loss: 2.3789 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 301/1800\n",
            "29/29 - 0s - loss: 1.7402 - accuracy: 0.4744 - val_loss: 2.3766 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 302/1800\n",
            "29/29 - 0s - loss: 1.7675 - accuracy: 0.4555 - val_loss: 2.3747 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 303/1800\n",
            "29/29 - 0s - loss: 1.7437 - accuracy: 0.4625 - val_loss: 2.3728 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 304/1800\n",
            "29/29 - 0s - loss: 1.7532 - accuracy: 0.4630 - val_loss: 2.3713 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 305/1800\n",
            "29/29 - 0s - loss: 1.8415 - accuracy: 0.4404 - val_loss: 2.3707 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 306/1800\n",
            "29/29 - 0s - loss: 1.7263 - accuracy: 0.4582 - val_loss: 2.3690 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 307/1800\n",
            "29/29 - 0s - loss: 1.6919 - accuracy: 0.4765 - val_loss: 2.3677 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 308/1800\n",
            "29/29 - 0s - loss: 1.7451 - accuracy: 0.4711 - val_loss: 2.3659 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 309/1800\n",
            "29/29 - 0s - loss: 1.7478 - accuracy: 0.4571 - val_loss: 2.3643 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 310/1800\n",
            "29/29 - 0s - loss: 1.6755 - accuracy: 0.4765 - val_loss: 2.3631 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 311/1800\n",
            "29/29 - 0s - loss: 1.6934 - accuracy: 0.4744 - val_loss: 2.3614 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 312/1800\n",
            "29/29 - 0s - loss: 1.7074 - accuracy: 0.4749 - val_loss: 2.3597 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 313/1800\n",
            "29/29 - 0s - loss: 1.7098 - accuracy: 0.4754 - val_loss: 2.3585 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 314/1800\n",
            "29/29 - 0s - loss: 1.6954 - accuracy: 0.4830 - val_loss: 2.3570 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 315/1800\n",
            "29/29 - 0s - loss: 1.6714 - accuracy: 0.4749 - val_loss: 2.3550 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 316/1800\n",
            "29/29 - 0s - loss: 1.7183 - accuracy: 0.4636 - val_loss: 2.3532 - val_accuracy: 0.5172 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 317/1800\n",
            "29/29 - 0s - loss: 1.6966 - accuracy: 0.4690 - val_loss: 2.3516 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 318/1800\n",
            "29/29 - 0s - loss: 1.7127 - accuracy: 0.4771 - val_loss: 2.3498 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 319/1800\n",
            "29/29 - 0s - loss: 1.6305 - accuracy: 0.4927 - val_loss: 2.3479 - val_accuracy: 0.5129 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 320/1800\n",
            "29/29 - 0s - loss: 1.6665 - accuracy: 0.4857 - val_loss: 2.3467 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 321/1800\n",
            "29/29 - 0s - loss: 1.7201 - accuracy: 0.4598 - val_loss: 2.3458 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 322/1800\n",
            "29/29 - 0s - loss: 1.6583 - accuracy: 0.4609 - val_loss: 2.3447 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 323/1800\n",
            "29/29 - 0s - loss: 1.6901 - accuracy: 0.4609 - val_loss: 2.3438 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 324/1800\n",
            "29/29 - 0s - loss: 1.6800 - accuracy: 0.4722 - val_loss: 2.3424 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 325/1800\n",
            "29/29 - 0s - loss: 1.6820 - accuracy: 0.4760 - val_loss: 2.3410 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 326/1800\n",
            "29/29 - 0s - loss: 1.5991 - accuracy: 0.4911 - val_loss: 2.3396 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 83ms/epoch - 3ms/step\n",
            "Epoch 327/1800\n",
            "29/29 - 0s - loss: 1.6769 - accuracy: 0.4657 - val_loss: 2.3387 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 328/1800\n",
            "29/29 - 0s - loss: 1.6525 - accuracy: 0.4814 - val_loss: 2.3383 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 329/1800\n",
            "29/29 - 0s - loss: 1.6401 - accuracy: 0.4798 - val_loss: 2.3363 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 330/1800\n",
            "29/29 - 0s - loss: 1.6544 - accuracy: 0.4781 - val_loss: 2.3343 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 331/1800\n",
            "29/29 - 0s - loss: 1.6276 - accuracy: 0.5046 - val_loss: 2.3331 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 332/1800\n",
            "29/29 - 0s - loss: 1.6217 - accuracy: 0.4960 - val_loss: 2.3319 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 333/1800\n",
            "29/29 - 0s - loss: 1.6731 - accuracy: 0.4711 - val_loss: 2.3312 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 334/1800\n",
            "29/29 - 0s - loss: 1.6080 - accuracy: 0.4873 - val_loss: 2.3300 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 335/1800\n",
            "29/29 - 0s - loss: 1.6474 - accuracy: 0.4825 - val_loss: 2.3288 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 336/1800\n",
            "29/29 - 0s - loss: 1.6333 - accuracy: 0.4760 - val_loss: 2.3287 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 337/1800\n",
            "29/29 - 0s - loss: 1.6322 - accuracy: 0.4674 - val_loss: 2.3277 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 338/1800\n",
            "29/29 - 0s - loss: 1.6100 - accuracy: 0.4906 - val_loss: 2.3261 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 339/1800\n",
            "29/29 - 0s - loss: 1.6065 - accuracy: 0.4889 - val_loss: 2.3250 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 340/1800\n",
            "29/29 - 0s - loss: 1.5866 - accuracy: 0.4954 - val_loss: 2.3247 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 341/1800\n",
            "29/29 - 0s - loss: 1.6187 - accuracy: 0.4906 - val_loss: 2.3232 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 342/1800\n",
            "29/29 - 0s - loss: 1.6087 - accuracy: 0.4960 - val_loss: 2.3234 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 343/1800\n",
            "29/29 - 0s - loss: 1.6344 - accuracy: 0.4835 - val_loss: 2.3231 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 344/1800\n",
            "29/29 - 0s - loss: 1.5904 - accuracy: 0.4933 - val_loss: 2.3224 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 345/1800\n",
            "29/29 - 0s - loss: 1.6092 - accuracy: 0.4857 - val_loss: 2.3208 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 346/1800\n",
            "29/29 - 0s - loss: 1.6183 - accuracy: 0.4792 - val_loss: 2.3201 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 347/1800\n",
            "29/29 - 0s - loss: 1.5864 - accuracy: 0.4949 - val_loss: 2.3192 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 348/1800\n",
            "29/29 - 0s - loss: 1.5806 - accuracy: 0.4965 - val_loss: 2.3174 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 349/1800\n",
            "29/29 - 0s - loss: 1.5771 - accuracy: 0.4787 - val_loss: 2.3167 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 350/1800\n",
            "29/29 - 0s - loss: 1.6376 - accuracy: 0.4641 - val_loss: 2.3163 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 351/1800\n",
            "29/29 - 0s - loss: 1.6067 - accuracy: 0.4884 - val_loss: 2.3166 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 352/1800\n",
            "29/29 - 0s - loss: 1.6128 - accuracy: 0.4862 - val_loss: 2.3158 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 353/1800\n",
            "29/29 - 0s - loss: 1.5885 - accuracy: 0.4992 - val_loss: 2.3144 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 354/1800\n",
            "29/29 - 0s - loss: 1.5357 - accuracy: 0.5262 - val_loss: 2.3138 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 355/1800\n",
            "29/29 - 0s - loss: 1.6302 - accuracy: 0.4722 - val_loss: 2.3135 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 356/1800\n",
            "29/29 - 0s - loss: 1.5824 - accuracy: 0.5116 - val_loss: 2.3132 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 357/1800\n",
            "29/29 - 0s - loss: 1.5592 - accuracy: 0.4965 - val_loss: 2.3113 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 358/1800\n",
            "29/29 - 0s - loss: 1.5508 - accuracy: 0.5008 - val_loss: 2.3099 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 359/1800\n",
            "29/29 - 0s - loss: 1.5854 - accuracy: 0.4868 - val_loss: 2.3098 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 360/1800\n",
            "29/29 - 0s - loss: 1.5715 - accuracy: 0.4808 - val_loss: 2.3086 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 361/1800\n",
            "29/29 - 0s - loss: 1.6036 - accuracy: 0.5013 - val_loss: 2.3078 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 362/1800\n",
            "29/29 - 0s - loss: 1.5993 - accuracy: 0.4733 - val_loss: 2.3070 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 363/1800\n",
            "29/29 - 0s - loss: 1.5640 - accuracy: 0.5127 - val_loss: 2.3069 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 364/1800\n",
            "29/29 - 0s - loss: 1.5361 - accuracy: 0.4997 - val_loss: 2.3054 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 365/1800\n",
            "29/29 - 0s - loss: 1.5880 - accuracy: 0.4970 - val_loss: 2.3044 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 366/1800\n",
            "29/29 - 0s - loss: 1.5763 - accuracy: 0.4889 - val_loss: 2.3031 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 367/1800\n",
            "29/29 - 0s - loss: 1.5457 - accuracy: 0.4981 - val_loss: 2.3029 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 368/1800\n",
            "29/29 - 0s - loss: 1.5102 - accuracy: 0.5154 - val_loss: 2.3021 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 369/1800\n",
            "29/29 - 0s - loss: 1.5258 - accuracy: 0.4965 - val_loss: 2.3017 - val_accuracy: 0.4957 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 370/1800\n",
            "29/29 - 0s - loss: 1.5446 - accuracy: 0.4825 - val_loss: 2.3013 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 371/1800\n",
            "29/29 - 0s - loss: 1.5422 - accuracy: 0.5100 - val_loss: 2.3001 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 372/1800\n",
            "29/29 - 0s - loss: 1.5159 - accuracy: 0.5251 - val_loss: 2.2999 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 373/1800\n",
            "29/29 - 0s - loss: 1.5387 - accuracy: 0.5035 - val_loss: 2.2990 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 374/1800\n",
            "29/29 - 0s - loss: 1.4948 - accuracy: 0.5084 - val_loss: 2.2973 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 82ms/epoch - 3ms/step\n",
            "Epoch 375/1800\n",
            "29/29 - 0s - loss: 1.5182 - accuracy: 0.4965 - val_loss: 2.2966 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 91ms/epoch - 3ms/step\n",
            "Epoch 376/1800\n",
            "29/29 - 0s - loss: 1.4709 - accuracy: 0.5121 - val_loss: 2.2964 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 377/1800\n",
            "29/29 - 0s - loss: 1.5320 - accuracy: 0.4954 - val_loss: 2.2958 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 378/1800\n",
            "29/29 - 0s - loss: 1.5510 - accuracy: 0.4981 - val_loss: 2.2951 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 379/1800\n",
            "29/29 - 0s - loss: 1.5203 - accuracy: 0.5089 - val_loss: 2.2947 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 380/1800\n",
            "29/29 - 0s - loss: 1.5393 - accuracy: 0.5046 - val_loss: 2.2947 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 381/1800\n",
            "29/29 - 0s - loss: 1.5099 - accuracy: 0.5170 - val_loss: 2.2948 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 382/1800\n",
            "29/29 - 0s - loss: 1.5063 - accuracy: 0.5073 - val_loss: 2.2950 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 383/1800\n",
            "29/29 - 0s - loss: 1.4844 - accuracy: 0.5138 - val_loss: 2.2941 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 384/1800\n",
            "29/29 - 0s - loss: 1.4885 - accuracy: 0.5067 - val_loss: 2.2936 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 385/1800\n",
            "29/29 - 0s - loss: 1.5033 - accuracy: 0.5046 - val_loss: 2.2932 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 386/1800\n",
            "29/29 - 0s - loss: 1.4778 - accuracy: 0.5186 - val_loss: 2.2918 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 387/1800\n",
            "29/29 - 0s - loss: 1.5234 - accuracy: 0.4981 - val_loss: 2.2914 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 388/1800\n",
            "29/29 - 0s - loss: 1.5323 - accuracy: 0.4987 - val_loss: 2.2911 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 389/1800\n",
            "29/29 - 0s - loss: 1.4797 - accuracy: 0.5197 - val_loss: 2.2905 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 390/1800\n",
            "29/29 - 0s - loss: 1.5128 - accuracy: 0.5003 - val_loss: 2.2899 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 391/1800\n",
            "29/29 - 0s - loss: 1.5297 - accuracy: 0.4868 - val_loss: 2.2896 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 81ms/epoch - 3ms/step\n",
            "Epoch 392/1800\n",
            "29/29 - 0s - loss: 1.4185 - accuracy: 0.5273 - val_loss: 2.2904 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 393/1800\n",
            "29/29 - 0s - loss: 1.5232 - accuracy: 0.5008 - val_loss: 2.2905 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 394/1800\n",
            "29/29 - 0s - loss: 1.4581 - accuracy: 0.5148 - val_loss: 2.2895 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 395/1800\n",
            "29/29 - 0s - loss: 1.4399 - accuracy: 0.5343 - val_loss: 2.2891 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 396/1800\n",
            "29/29 - 0s - loss: 1.4765 - accuracy: 0.5051 - val_loss: 2.2885 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 397/1800\n",
            "29/29 - 0s - loss: 1.4052 - accuracy: 0.5267 - val_loss: 2.2880 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 398/1800\n",
            "29/29 - 0s - loss: 1.4882 - accuracy: 0.5084 - val_loss: 2.2879 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 80ms/epoch - 3ms/step\n",
            "Epoch 399/1800\n",
            "29/29 - 0s - loss: 1.4900 - accuracy: 0.4911 - val_loss: 2.2875 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 400/1800\n",
            "29/29 - 0s - loss: 1.4366 - accuracy: 0.5397 - val_loss: 2.2870 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 77ms/epoch - 3ms/step\n",
            "Epoch 401/1800\n",
            "29/29 - 0s - loss: 1.4642 - accuracy: 0.5283 - val_loss: 2.2871 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 402/1800\n",
            "29/29 - 0s - loss: 1.4493 - accuracy: 0.5289 - val_loss: 2.2876 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 403/1800\n",
            "29/29 - 0s - loss: 1.4680 - accuracy: 0.5116 - val_loss: 2.2880 - val_accuracy: 0.5043 - lr: 1.0000e-04 - 78ms/epoch - 3ms/step\n",
            "Epoch 404/1800\n",
            "29/29 - 0s - loss: 1.4758 - accuracy: 0.5073 - val_loss: 2.2883 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 77ms/epoch - 3ms/step\n",
            "Epoch 405/1800\n",
            "29/29 - 0s - loss: 1.5090 - accuracy: 0.4906 - val_loss: 2.2877 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 406/1800\n",
            "29/29 - 0s - loss: 1.4467 - accuracy: 0.5154 - val_loss: 2.2882 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 407/1800\n",
            "29/29 - 0s - loss: 1.4598 - accuracy: 0.5116 - val_loss: 2.2882 - val_accuracy: 0.5086 - lr: 1.0000e-04 - 79ms/epoch - 3ms/step\n",
            "Epoch 408/1800\n",
            "29/29 - 0s - loss: 1.4507 - accuracy: 0.5224 - val_loss: 2.2882 - val_accuracy: 0.5043 - lr: 1.0000e-05 - 76ms/epoch - 3ms/step\n",
            "Epoch 409/1800\n",
            "29/29 - 0s - loss: 1.5020 - accuracy: 0.5078 - val_loss: 2.2881 - val_accuracy: 0.5086 - lr: 1.0000e-05 - 78ms/epoch - 3ms/step\n",
            "Epoch 410/1800\n",
            "29/29 - 0s - loss: 1.4459 - accuracy: 0.5289 - val_loss: 2.2880 - val_accuracy: 0.5086 - lr: 1.0000e-05 - 81ms/epoch - 3ms/step\n",
            "Epoch 411/1800\n",
            "29/29 - 0s - loss: 1.4310 - accuracy: 0.5219 - val_loss: 2.2881 - val_accuracy: 0.5086 - lr: 1.0000e-05 - 81ms/epoch - 3ms/step\n",
            "Epoch 412/1800\n",
            "29/29 - 0s - loss: 1.4675 - accuracy: 0.5192 - val_loss: 2.2880 - val_accuracy: 0.5086 - lr: 1.0000e-05 - 79ms/epoch - 3ms/step\n",
            "Epoch 413/1800\n",
            "29/29 - 0s - loss: 1.4382 - accuracy: 0.5078 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-05 - 80ms/epoch - 3ms/step\n",
            "Epoch 414/1800\n",
            "29/29 - 0s - loss: 1.4401 - accuracy: 0.5294 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-05 - 81ms/epoch - 3ms/step\n",
            "Epoch 415/1800\n",
            "29/29 - 0s - loss: 1.4300 - accuracy: 0.5434 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-06 - 82ms/epoch - 3ms/step\n",
            "Epoch 416/1800\n",
            "29/29 - 0s - loss: 1.4457 - accuracy: 0.5105 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-06 - 82ms/epoch - 3ms/step\n",
            "Epoch 417/1800\n",
            "29/29 - 0s - loss: 1.4106 - accuracy: 0.5332 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-06 - 79ms/epoch - 3ms/step\n",
            "Epoch 418/1800\n",
            "29/29 - 0s - loss: 1.4517 - accuracy: 0.5127 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-06 - 80ms/epoch - 3ms/step\n",
            "Epoch 419/1800\n",
            "29/29 - 0s - loss: 1.4392 - accuracy: 0.5154 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-06 - 79ms/epoch - 3ms/step\n",
            "Epoch 420/1800\n",
            "29/29 - 0s - loss: 1.4210 - accuracy: 0.5202 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-06 - 79ms/epoch - 3ms/step\n",
            "Epoch 421/1800\n",
            "29/29 - 0s - loss: 1.4096 - accuracy: 0.5175 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-06 - 80ms/epoch - 3ms/step\n",
            "Epoch 422/1800\n",
            "29/29 - 0s - loss: 1.4286 - accuracy: 0.5326 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-07 - 81ms/epoch - 3ms/step\n",
            "Epoch 423/1800\n",
            "29/29 - 0s - loss: 1.4453 - accuracy: 0.5229 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-07 - 79ms/epoch - 3ms/step\n",
            "Epoch 424/1800\n",
            "29/29 - 0s - loss: 1.4650 - accuracy: 0.5186 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-07 - 79ms/epoch - 3ms/step\n",
            "Epoch 425/1800\n",
            "29/29 - 0s - loss: 1.4100 - accuracy: 0.5440 - val_loss: 2.2878 - val_accuracy: 0.5086 - lr: 1.0000e-07 - 80ms/epoch - 3ms/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=25, verbose=0, mode='min')  \n",
        "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                  factor=0.1, patience=7, verbose=0, min_delta=1e-119, mode='min')\n",
        "history = model1.fit(train_x, y_train, validation_data=(valid_x, y_valid), class_weight=class_weights_dict45,\n",
        "            shuffle=True, verbose=2, epochs=1800, batch_size=64,\n",
        "            callbacks=[earlyStopping, checkpoint_mlp, reduce_lr_loss])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "from keras.models import load_model\n",
        "best_model = load_model(filepath_mlp)"
      ],
      "metadata": {
        "id": "iGHXy6V2gONJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "DsUtgBRqOj8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d66f37-887c-44b8-b07e-8b83079b90a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.52"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "valid_accuracy = round(best_model.evaluate(valid_x, y_valid, verbose=0, batch_size=64)[1], 2)\n",
        "valid_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ScVSLvv4fDv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd07d7d0-f7be-40c4-9739-bd28dd27d622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       1.00      0.50      0.67         2\n",
            "           7       0.50      0.33      0.40         6\n",
            "           8       1.00      0.67      0.80         3\n",
            "           9       0.33      0.33      0.33         3\n",
            "          10       0.50      0.67      0.57         3\n",
            "          11       0.50      0.50      0.50         2\n",
            "          12       0.00      0.00      0.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       0.50      0.67      0.57         6\n",
            "          15       0.62      0.56      0.59         9\n",
            "          16       0.00      0.00      0.00         2\n",
            "          17       1.00      1.00      1.00         2\n",
            "          18       1.00      1.00      1.00         3\n",
            "          19       0.50      0.50      0.50         2\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       1.00      0.50      0.67         2\n",
            "          22       0.60      0.75      0.67         4\n",
            "          23       0.56      0.71      0.63         7\n",
            "          24       0.00      0.00      0.00         3\n",
            "          25       1.00      0.25      0.40         4\n",
            "          26       0.00      0.00      0.00         2\n",
            "          27       0.00      0.00      0.00         2\n",
            "          28       1.00      1.00      1.00         2\n",
            "          29       1.00      1.00      1.00         4\n",
            "          30       0.90      0.90      0.90        10\n",
            "          31       0.67      0.67      0.67         3\n",
            "          32       0.33      0.43      0.38         7\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.11      0.29      0.15         7\n",
            "          35       0.00      0.00      0.00         4\n",
            "          36       1.00      0.44      0.62         9\n",
            "          37       0.50      0.50      0.50         2\n",
            "          38       0.00      0.00      0.00         4\n",
            "          39       0.33      0.50      0.40         2\n",
            "          40       0.67      1.00      0.80         2\n",
            "          41       0.14      0.50      0.22         2\n",
            "          42       0.67      0.67      0.67         3\n",
            "          43       0.00      0.00      0.00         2\n",
            "          44       0.40      0.50      0.44         4\n",
            "          45       0.50      1.00      0.67         2\n",
            "          46       0.30      0.50      0.37         6\n",
            "          47       0.36      0.89      0.52         9\n",
            "          48       0.00      0.00      0.00         2\n",
            "          49       1.00      0.50      0.67         2\n",
            "          50       1.00      1.00      1.00         1\n",
            "          51       0.57      1.00      0.73         4\n",
            "          52       1.00      0.50      0.67         2\n",
            "          53       1.00      0.75      0.86         4\n",
            "          54       1.00      0.25      0.40         4\n",
            "          55       1.00      1.00      1.00         2\n",
            "          56       1.00      0.50      0.67         2\n",
            "          57       0.33      0.67      0.44         3\n",
            "          58       1.00      0.50      0.67         2\n",
            "          59       1.00      0.50      0.67         2\n",
            "          60       0.50      1.00      0.67         2\n",
            "          61       0.00      0.00      0.00         2\n",
            "          62       1.00      0.50      0.67         2\n",
            "          63       0.33      0.50      0.40         2\n",
            "          64       0.00      0.00      0.00         4\n",
            "          65       1.00      0.50      0.67         2\n",
            "          66       1.00      0.50      0.67         2\n",
            "          67       1.00      1.00      1.00         2\n",
            "          68       0.67      0.67      0.67         3\n",
            "          69       0.75      0.38      0.50         8\n",
            "\n",
            "    accuracy                           0.52       232\n",
            "   macro avg       0.58      0.51      0.51       232\n",
            "weighted avg       0.57      0.52      0.51       232\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.50      0.50      0.50         2\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         2\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       1.00      0.50      0.67         2\n",
            "           7       0.30      0.50      0.37         6\n",
            "           8       1.00      1.00      1.00         2\n",
            "           9       0.50      0.67      0.57         3\n",
            "          10       0.00      0.00      0.00         2\n",
            "          11       1.00      0.50      0.67         2\n",
            "          12       0.00      0.00      0.00         2\n",
            "          13       0.50      0.50      0.50         2\n",
            "          14       0.71      0.83      0.77         6\n",
            "          15       0.62      0.50      0.56        10\n",
            "          16       0.50      1.00      0.67         2\n",
            "          17       0.00      0.00      0.00         2\n",
            "          18       0.33      0.33      0.33         3\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.50      0.33      0.40         3\n",
            "          22       0.75      0.75      0.75         4\n",
            "          23       0.36      0.57      0.44         7\n",
            "          24       1.00      1.00      1.00         2\n",
            "          25       0.00      0.00      0.00         4\n",
            "          26       0.00      0.00      0.00         2\n",
            "          27       0.00      0.00      0.00         2\n",
            "          28       1.00      1.00      1.00         1\n",
            "          29       1.00      1.00      1.00         5\n",
            "          30       1.00      0.80      0.89        10\n",
            "          31       0.75      1.00      0.86         3\n",
            "          32       0.45      0.71      0.56         7\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.09      0.14      0.11         7\n",
            "          35       0.67      0.40      0.50         5\n",
            "          36       0.64      0.88      0.74         8\n",
            "          37       0.67      1.00      0.80         2\n",
            "          38       0.40      0.50      0.44         4\n",
            "          39       1.00      0.50      0.67         2\n",
            "          40       0.20      0.50      0.29         2\n",
            "          41       0.50      0.50      0.50         2\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       0.33      0.50      0.40         2\n",
            "          44       0.67      1.00      0.80         4\n",
            "          45       0.67      1.00      0.80         2\n",
            "          46       0.50      0.50      0.50         6\n",
            "          47       0.29      0.40      0.33        10\n",
            "          48       0.00      0.00      0.00         2\n",
            "          49       1.00      0.50      0.67         2\n",
            "          50       0.67      1.00      0.80         2\n",
            "          51       1.00      0.75      0.86         4\n",
            "          52       0.25      0.50      0.33         2\n",
            "          53       0.75      0.75      0.75         4\n",
            "          54       0.50      0.50      0.50         4\n",
            "          55       0.00      0.00      0.00         2\n",
            "          56       0.50      0.50      0.50         2\n",
            "          57       0.25      0.33      0.29         3\n",
            "          58       1.00      1.00      1.00         2\n",
            "          59       1.00      1.00      1.00         2\n",
            "          60       0.67      1.00      0.80         2\n",
            "          61       0.00      0.00      0.00         2\n",
            "          62       1.00      0.50      0.67         2\n",
            "          63       0.00      0.00      0.00         2\n",
            "          64       1.00      0.25      0.40         4\n",
            "          65       1.00      0.33      0.50         3\n",
            "          66       0.00      0.00      0.00         2\n",
            "          67       0.67      1.00      0.80         2\n",
            "          68       0.00      0.00      0.00         2\n",
            "          69       0.57      0.50      0.53         8\n",
            "\n",
            "    accuracy                           0.51       232\n",
            "   macro avg       0.49      0.48      0.46       232\n",
            "weighted avg       0.51      0.51      0.49       232\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model \n",
        "from sklearn.metrics import classification_report\n",
        "assert list(y_test)[0:5] == [10, 47, 20, 23, 25]\n",
        "print(classification_report(y_valid, np.array(best_model.predict(valid_x).argmax(-1)),))\n",
        "print(classification_report(y_test, np.array(best_model.predict(test_x).argmax(-1)),))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnTRonUbnyqb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "f1194d57-bd16-437e-c2ef-bc4eb43f236e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Training curves\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc = 'upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# References\n",
        "# https://future-chem.com/rdkit-google-colab/#toc5\n",
        "# https://www.rdkit.org/docs/index.html"
      ],
      "metadata": {
        "id": "dmteC1TiiXFE"
      },
      "execution_count": 46,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}