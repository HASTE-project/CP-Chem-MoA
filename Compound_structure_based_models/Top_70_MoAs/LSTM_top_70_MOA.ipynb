{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3292f556d4174aebb6e1b8fddba8b0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8099f866f056490fbe4b0041efd1f71d",
              "IPY_MODEL_3dd28732d71546219948891607d53f97",
              "IPY_MODEL_6522bae46fcc49fc92300e14d0f73cf2"
            ],
            "layout": "IPY_MODEL_ef7f37fad4c34839a84bb8e43f6480e5"
          }
        },
        "8099f866f056490fbe4b0041efd1f71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ca9bf6e9955475f911f8aa129eb53bd",
            "placeholder": "​",
            "style": "IPY_MODEL_e15fbc7061604d4f877509e81de2ab4a",
            "value": ""
          }
        },
        "3dd28732d71546219948891607d53f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b78d2aeb7cc1430790c6aef975d259be",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a5c22e901284bbb98f8a9067622babb",
            "value": 0
          }
        },
        "6522bae46fcc49fc92300e14d0f73cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa8d642891e24ead80c35dfea75a5b1e",
            "placeholder": "​",
            "style": "IPY_MODEL_2130850be7ba4a16a023a06c295fdb82",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "ef7f37fad4c34839a84bb8e43f6480e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ca9bf6e9955475f911f8aa129eb53bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e15fbc7061604d4f877509e81de2ab4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b78d2aeb7cc1430790c6aef975d259be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2a5c22e901284bbb98f8a9067622babb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa8d642891e24ead80c35dfea75a5b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2130850be7ba4a16a023a06c295fdb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2z1un11J3mNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bd1394-70a2-4b5d-ad9d-3b69c7e1698c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "['/content',\n",
            " '/env/python',\n",
            " '/usr/lib/python37.zip',\n",
            " '/usr/lib/python3.7',\n",
            " '/usr/lib/python3.7/lib-dynload',\n",
            " '',\n",
            " '/usr/local/lib/python3.7/dist-packages',\n",
            " '/usr/lib/python3/dist-packages',\n",
            " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
            " '/root/.ipython',\n",
            " '/usr/local/lib/python3.7/site-packages/']\n",
            "['/usr/local/lib/python3.7/site-packages']\n"
          ]
        }
      ],
      "source": [
        "# install rdkit  \n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y -c rdkit rdkit python=3.7\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "import pprint     \n",
        "pprint.pprint(sys.path)\n",
        "!python -c \"import site; print (site.getsitepackages())\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omxK7KFWA7KJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a110291-c5a8-4643-9169-b6178b7ff63f"
      },
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q SmilesPE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m752.6/752.6 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "3292f556d4174aebb6e1b8fddba8b0a3",
            "8099f866f056490fbe4b0041efd1f71d",
            "3dd28732d71546219948891607d53f97",
            "6522bae46fcc49fc92300e14d0f73cf2",
            "ef7f37fad4c34839a84bb8e43f6480e5",
            "5ca9bf6e9955475f911f8aa129eb53bd",
            "e15fbc7061604d4f877509e81de2ab4a",
            "b78d2aeb7cc1430790c6aef975d259be",
            "2a5c22e901284bbb98f8a9067622babb",
            "fa8d642891e24ead80c35dfea75a5b1e",
            "2130850be7ba4a16a023a06c295fdb82"
          ]
        },
        "id": "vcZWmBn933IQ",
        "outputId": "df7d6102-51e4-428b-ca20-201481cc533d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3292f556d4174aebb6e1b8fddba8b0a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.22.0.dev0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from SmilesPE.tokenizer import *"
      ],
      "metadata": {
        "id": "9cjcWuPAuV6n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizaion classes for huggingface interface\n",
        "# reference: https://github.com/huggingface/transformers/blob/master/src/transformers/tokenization_bert.py\n",
        "# reference https://github.com/rxn4chemistry/rxnmapper\n",
        "\n",
        "import collections\n",
        "import logging\n",
        "import os\n",
        "import re\n",
        "import codecs\n",
        "import unicodedata\n",
        "from typing import List, Optional\n",
        "from transformers import PreTrainedTokenizer\n",
        "from SmilesPE.tokenizer import SPE_Tokenizer\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
        "    vocab = collections.OrderedDict()\n",
        "    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
        "        tokens = reader.readlines()\n",
        "    for index, token in enumerate(tokens):\n",
        "        token = token.rstrip(\"\\n\")\n",
        "        vocab[token] = index\n",
        "    return vocab\n",
        "\n",
        "class Atomwise_Tokenizer(object):\n",
        "    \"\"\"Run atom-level SMILES tokenization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\" Constructs a atom-level Tokenizer.\n",
        "        \"\"\"\n",
        "        self.regex_pattern = r\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
        "        self.regex = re.compile(self.regex_pattern)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\" Basic Tokenization of a SMILES.\n",
        "        \"\"\"\n",
        "        tokens = [token for token in self.regex.findall(text)]\n",
        "        return tokens\n",
        "    \n",
        "class SMILES_SPE_Tokenizer(PreTrainedTokenizer):\n",
        "    r\"\"\"\n",
        "    Constructs a SMILES tokenizer. Based on SMILES Pair Encoding (https://github.com/XinhaoLi74/SmilesPE).\n",
        "    This tokenizer inherits from :class:`~transformers.PreTrainedTokenizer` which contains most of the methods. Users\n",
        "    should refer to the superclass for more information regarding methods.\n",
        "    Args:\n",
        "        vocab_file (:obj:`string`):\n",
        "            File containing the vocabulary.\n",
        "        spe_file (:obj:`string`):\n",
        "            File containing the trained SMILES Pair Encoding vocabulary.\n",
        "        unk_token (:obj:`string`, `optional`, defaults to \"[UNK]\"):\n",
        "            The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this\n",
        "            token instead.\n",
        "        sep_token (:obj:`string`, `optional`, defaults to \"[SEP]\"):\n",
        "            The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences\n",
        "            for sequence classification or for a text and a question for question answering.\n",
        "            It is also used as the last token of a sequence built with special tokens.\n",
        "        pad_token (:obj:`string`, `optional`, defaults to \"[PAD]\"):\n",
        "            The token used for padding, for example when batching sequences of different lengths.\n",
        "        cls_token (:obj:`string`, `optional`, defaults to \"[CLS]\"):\n",
        "            The classifier token which is used when doing sequence classification (classification of the whole\n",
        "            sequence instead of per-token classification). It is the first token of the sequence when built with\n",
        "            special tokens.\n",
        "        mask_token (:obj:`string`, `optional`, defaults to \"[MASK]\"):\n",
        "            The token used for masking values. This is the token used when training this model with masked language\n",
        "            modeling. This is the token which the model will try to predict.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_file,\n",
        "        spe_file,\n",
        "        unk_token=\"[UNK]\",\n",
        "        sep_token=\"[SEP]\",\n",
        "        pad_token=\"[PAD]\",\n",
        "        cls_token=\"[CLS]\",\n",
        "        mask_token=\"[MASK]\",\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        if not os.path.isfile(vocab_file):\n",
        "            raise ValueError(\n",
        "                \"Can't find a vocabulary file at path '{}'.\".format(vocab_file)\n",
        "            )\n",
        "        if not os.path.isfile(spe_file):\n",
        "            raise ValueError(\n",
        "                \"Can't find a SPE vocabulary file at path '{}'.\".format(spe_file)\n",
        "            )\n",
        "        self.vocab = load_vocab(vocab_file)\n",
        "        self.spe_vocab = codecs.open(spe_file)\n",
        "        self.ids_to_tokens = collections.OrderedDict([(ids, tok) for tok, ids in self.vocab.items()])\n",
        "        self.spe_tokenizer = SPE_Tokenizer(self.spe_vocab)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.vocab)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return dict(self.vocab, **self.added_tokens_encoder)\n",
        "\n",
        "    def _tokenize(self, text):\n",
        "        return self.spe_tokenizer.tokenize(text).split(' ')\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str) in an id using the vocab. \"\"\"\n",
        "        return self.vocab.get(token, self.vocab.get(self.unk_token))\n",
        "\n",
        "    def _convert_id_to_token(self, index):\n",
        "        \"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"\n",
        "        return self.ids_to_tokens.get(index, self.unk_token)\n",
        "\n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"\n",
        "        out_string = \" \".join(tokens).replace(\" ##\", \"\").strip()\n",
        "        return out_string\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A BERT sequence has the following format:\n",
        "        - single sequence: ``[CLS] X [SEP]``\n",
        "        - pair of sequences: ``[CLS] A [SEP] B [SEP]``\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of IDs to which the special tokens will be added\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "        Returns:\n",
        "            :obj:`List[int]`: list of `input IDs <../glossary.html#input-ids>`__ with the appropriate special tokens.\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        "\n",
        "    def get_special_tokens_mask(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None, already_has_special_tokens: bool = False\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` method.\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of ids.\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "            already_has_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
        "                Set to True if the token list is already formatted with special tokens for the model\n",
        "        Returns:\n",
        "            :obj:`List[int]`: A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n",
        "        \"\"\"\n",
        "\n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        "\n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "\n",
        "    def create_token_type_ids_from_sequences(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A BERT sequence pair mask has the following format:\n",
        "        ::\n",
        "            0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
        "            | first sequence    | second sequence |\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of ids.\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "        Returns:\n",
        "            :obj:`List[int]`: List of `token type IDs <../glossary.html#token-type-ids>`_ according to the given\n",
        "            sequence(s).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        "\n",
        "    def save_vocabulary(self, vocab_path):\n",
        "        \"\"\"\n",
        "        Save the sentencepiece vocabulary (copy original file) and special tokens file to a directory.\n",
        "        Args:\n",
        "            vocab_path (:obj:`str`):\n",
        "                The directory in which to save the vocabulary.\n",
        "        Returns:\n",
        "            :obj:`Tuple(str)`: Paths to the files saved.\n",
        "        \"\"\"\n",
        "        index = 0\n",
        "        if os.path.isdir(vocab_path):\n",
        "            vocab_file = os.path.join(vocab_path, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        "        else:\n",
        "            vocab_file = vocab_path\n",
        "        with open(vocab_file, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.vocab.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(vocab_file)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        "        return (vocab_file,)\n",
        "\n",
        "class Atomwise_Tokenizer(object):\n",
        "    \"\"\"Run atom-level SMILES tokenization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\" Constructs a atom-level Tokenizer.\n",
        "        \"\"\"\n",
        "        self.regex_pattern = r\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
        "        self.regex = re.compile(self.regex_pattern)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\" Basic Tokenization of a SMILES.\n",
        "        \"\"\"\n",
        "        tokens = [token for token in self.regex.findall(text)]\n",
        "        return tokens\n",
        "\n",
        "class SMILES_Atomwise_Tokenizer(PreTrainedTokenizer):\n",
        "    r\"\"\"\n",
        "    Constructs a SMILES tokenizer. Based on SMILES Pair Encoding (https://github.com/XinhaoLi74/SmilesPE).\n",
        "    This tokenizer inherits from :class:`~transformers.PreTrainedTokenizer` which contains most of the methods. Users\n",
        "    should refer to the superclass for more information regarding methods.\n",
        "    Args:\n",
        "        vocab_file (:obj:`string`):\n",
        "            File containing the vocabulary.\n",
        "        unk_token (:obj:`string`, `optional`, defaults to \"[UNK]\"):\n",
        "            The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this\n",
        "            token instead.\n",
        "        sep_token (:obj:`string`, `optional`, defaults to \"[SEP]\"):\n",
        "            The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences\n",
        "            for sequence classification or for a text and a question for question answering.\n",
        "            It is also used as the last token of a sequence built with special tokens.\n",
        "        pad_token (:obj:`string`, `optional`, defaults to \"[PAD]\"):\n",
        "            The token used for padding, for example when batching sequences of different lengths.\n",
        "        cls_token (:obj:`string`, `optional`, defaults to \"[CLS]\"):\n",
        "            The classifier token which is used when doing sequence classification (classification of the whole\n",
        "            sequence instead of per-token classification). It is the first token of the sequence when built with\n",
        "            special tokens.\n",
        "        mask_token (:obj:`string`, `optional`, defaults to \"[MASK]\"):\n",
        "            The token used for masking values. This is the token used when training this model with masked language\n",
        "            modeling. This is the token which the model will try to predict.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_file,\n",
        "        unk_token=\"[UNK]\",\n",
        "        sep_token=\"[SEP]\",\n",
        "        pad_token=\"[PAD]\",\n",
        "        cls_token=\"[CLS]\",\n",
        "        mask_token=\"[MASK]\",\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        if not os.path.isfile(vocab_file):\n",
        "            raise ValueError(\n",
        "                \"Can't find a vocabulary file at path '{}'.\".format(vocab_file)\n",
        "            )\n",
        "        self.vocab = load_vocab(vocab_file)\n",
        "        self.ids_to_tokens = collections.OrderedDict([(ids, tok) for tok, ids in self.vocab.items()])\n",
        "        self.tokenizer = Atomwise_Tokenizer()\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.vocab)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return dict(self.vocab, **self.added_tokens_encoder)\n",
        "\n",
        "    def _tokenize(self, text):\n",
        "        return self.tokenizer.tokenize(text)\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str) in an id using the vocab. \"\"\"\n",
        "        return self.vocab.get(token, self.vocab.get(self.unk_token))\n",
        "\n",
        "    def _convert_id_to_token(self, index):\n",
        "        \"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"\n",
        "        return self.ids_to_tokens.get(index, self.unk_token)\n",
        "\n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"\n",
        "        out_string = \" \".join(tokens).replace(\" ##\", \"\").strip()\n",
        "        return out_string\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A BERT sequence has the following format:\n",
        "        - single sequence: ``[CLS] X [SEP]``\n",
        "        - pair of sequences: ``[CLS] A [SEP] B [SEP]``\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of IDs to which the special tokens will be added\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "        Returns:\n",
        "            :obj:`List[int]`: list of `input IDs <../glossary.html#input-ids>`__ with the appropriate special tokens.\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        "\n",
        "    def get_special_tokens_mask(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None, already_has_special_tokens: bool = False\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` method.\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of ids.\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "            already_has_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):\n",
        "                Set to True if the token list is already formatted with special tokens for the model\n",
        "        Returns:\n",
        "            :obj:`List[int]`: A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n",
        "        \"\"\"\n",
        "\n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        "\n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "\n",
        "    def create_token_type_ids_from_sequences(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A BERT sequence pair mask has the following format:\n",
        "        ::\n",
        "            0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
        "            | first sequence    | second sequence |\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        Args:\n",
        "            token_ids_0 (:obj:`List[int]`):\n",
        "                List of ids.\n",
        "            token_ids_1 (:obj:`List[int]`, `optional`, defaults to :obj:`None`):\n",
        "                Optional second list of IDs for sequence pairs.\n",
        "        Returns:\n",
        "            :obj:`List[int]`: List of `token type IDs <../glossary.html#token-type-ids>`_ according to the given\n",
        "            sequence(s).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        "\n",
        "    def save_vocabulary(self, vocab_path):\n",
        "        \"\"\"\n",
        "        Save the sentencepiece vocabulary (copy original file) and special tokens file to a directory.\n",
        "        Args:\n",
        "            vocab_path (:obj:`str`):\n",
        "                The directory in which to save the vocabulary.\n",
        "        Returns:\n",
        "            :obj:`Tuple(str)`: Paths to the files saved.\n",
        "        \"\"\"\n",
        "        index = 0\n",
        "        if os.path.isdir(vocab_path):\n",
        "            vocab_file = os.path.join(vocab_path, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        "        else:\n",
        "            vocab_file = vocab_path\n",
        "        with open(vocab_file, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.vocab.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(vocab_file)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        "        return (vocab_file,)\n",
        "\n"
      ],
      "metadata": {
        "id": "HQRrK3yz37rM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/XinhaoLi74/SmilesPE/master/SPE_ChEMBL.txt"
      ],
      "metadata": {
        "id": "5T8JYzCB37tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846fdb31-eb31-4706-e2ef-d537dfdb3a19"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-03 06:24:21--  https://raw.githubusercontent.com/XinhaoLi74/SmilesPE/master/SPE_ChEMBL.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27879 (27K) [text/plain]\n",
            "Saving to: ‘SPE_ChEMBL.txt’\n",
            "\n",
            "\rSPE_ChEMBL.txt        0%[                    ]       0  --.-KB/s               \rSPE_ChEMBL.txt      100%[===================>]  27.23K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-09-03 06:24:21 (11.5 MB/s) - ‘SPE_ChEMBL.txt’ saved [27879/27879]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some default tokens from huggingface\n",
        "default_toks = ['[PAD]', \n",
        "                '[unused1]', '[unused2]', '[unused3]', '[unused4]','[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', \n",
        "                '[UNK]', '[CLS]', '[SEP]', '[MASK]']\n",
        "\n",
        "# atom-level tokens used for trained the spe vocabulary\n",
        "atom_toks = ['[c-]', '[SeH]', '[N]', '[C@@]', '[Te]', '[OH+]', 'n', '[AsH]', '[B]', 'b', \n",
        "             '[S@@]', 'o', ')', '[NH+]', '[SH]', 'O', 'I', '[C@]', '-', '[As+]', '[Cl+2]', \n",
        "             '[P+]', '[o+]', '[C]', '[C@H]', '[CH2]', '\\\\', 'P', '[O-]', '[NH-]', '[S@@+]', \n",
        "             '[te]', '[s+]', 's', '[B-]', 'B', 'F', '=', '[te+]', '[H]', '[C@@H]', '[Na]', \n",
        "             '[Si]', '[CH2-]', '[S@+]', 'C', '[se+]', '[cH-]', '6', 'N', '[IH2]', '[As]', \n",
        "             '[Si@]', '[BH3-]', '[Se]', 'Br', '[C+]', '[I+3]', '[b-]', '[P@+]', '[SH2]', '[I+2]', \n",
        "             '%11', '[Ag-3]', '[O]', '9', 'c', '[N-]', '[BH-]', '4', '[N@+]', '[SiH]', '[Cl+3]', '#', \n",
        "             '(', '[O+]', '[S-]', '[Br+2]', '[nH]', '[N+]', '[n-]', '3', '[Se+]', '[P@@]', '[Zn]', '2', \n",
        "             '[NH2+]', '%10', '[SiH2]', '[nH+]', '[Si@@]', '[P@@+]', '/', '1', '[c+]', '[S@]', '[S+]', \n",
        "             '[SH+]', '[B@@-]', '8', '[B@-]', '[C-]', '7', '[P@]', '[se]', 'S', '[n+]', '[PH]', '[I+]', '5', 'p', '[BH2-]', '[N@@+]', '[CH]', 'Cl']\n",
        "\n",
        "# spe tokens\n",
        "with open('SPE_ChEMBL.txt', \"r\") as ins:\n",
        "    spe_toks = []\n",
        "    for line in ins:\n",
        "        spe_toks.append(line.split('\\n')[0])\n",
        "\n",
        "spe_tokens = []\n",
        "for s in spe_toks:\n",
        "    spe_tokens.append(''.join(s.split(' ')))\n",
        "print('Number of SMILES:', len(spe_toks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOJu2M_Y37wt",
        "outputId": "220c20d7-195e-47cd-931f-37084738a873"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of SMILES: 3002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spe_vocab = default_toks + atom_toks + spe_tokens\n",
        "len(spe_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEAMZwkV371d",
        "outputId": "788f85ef-5de4-4dac-814e-d4d8874a8cb7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3132"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('vocab_spe.txt', 'w') as f:\n",
        "    for voc in spe_vocab:\n",
        "        f.write(f'{voc}\\n')"
      ],
      "metadata": {
        "id": "zjp3seBZ374e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SMILES_SPE_Tokenizer(vocab_file='vocab_spe.txt', spe_file= 'SPE_ChEMBL.txt')"
      ],
      "metadata": {
        "id": "dJUsA6pP377D"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('top_70_MOAs.txt', sep = '\\t')\n",
        "df"
      ],
      "metadata": {
        "id": "H4cC0Iy_TFpT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "e8c38dc8-410a-4f7f-db8f-740cf7390d47"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 SMILES  \\\n",
              "0                       Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1   \n",
              "1                  OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N   \n",
              "2           O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12   \n",
              "3            O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1   \n",
              "4     O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...   \n",
              "...                                                 ...   \n",
              "2312  CCn1c(nc2c(ncc(OC[C@H]3CCCNC3)c12)C#CC(C)(C)O)...   \n",
              "2313                CCN(CC)CCCCN1c2ccccc2Oc2ccc(Cl)cc12   \n",
              "2314      CCCCCCCCCCCCCCCCCCOP(O)(=O)OC1CC[N+](C)(C)CC1   \n",
              "2315  Cc1n[nH]c2ccc(cc12)-c1cncc(OC[C@@H](N)Cc2ccccc...   \n",
              "2316  CC(C)NC[C@@H](C(=O)N1CCN(CC1)c1ncnc2[C@@H](O)C...   \n",
              "\n",
              "                                 MOA  \n",
              "0     adrenergic receptor antagonist  \n",
              "1     adrenergic receptor antagonist  \n",
              "2     adrenergic receptor antagonist  \n",
              "3     adrenergic receptor antagonist  \n",
              "4     adrenergic receptor antagonist  \n",
              "...                              ...  \n",
              "2312                   AKT inhibitor  \n",
              "2313                   AKT inhibitor  \n",
              "2314                   AKT inhibitor  \n",
              "2315                   AKT inhibitor  \n",
              "2316                   AKT inhibitor  \n",
              "\n",
              "[2317 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da762c50-4058-4ae6-b261-f70d2b77681f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2312</th>\n",
              "      <td>CCn1c(nc2c(ncc(OC[C@H]3CCCNC3)c12)C#CC(C)(C)O)...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2313</th>\n",
              "      <td>CCN(CC)CCCCN1c2ccccc2Oc2ccc(Cl)cc12</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2314</th>\n",
              "      <td>CCCCCCCCCCCCCCCCCCOP(O)(=O)OC1CC[N+](C)(C)CC1</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2315</th>\n",
              "      <td>Cc1n[nH]c2ccc(cc12)-c1cncc(OC[C@@H](N)Cc2ccccc...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2316</th>\n",
              "      <td>CC(C)NC[C@@H](C(=O)N1CCN(CC1)c1ncnc2[C@@H](O)C...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2317 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da762c50-4058-4ae6-b261-f70d2b77681f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da762c50-4058-4ae6-b261-f70d2b77681f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da762c50-4058-4ae6-b261-f70d2b77681f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the duplicates \n",
        "for i in df.SMILES.tolist():\n",
        "  if df.SMILES.tolist().count(i) != 1:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "LJvorpq-t-1t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MOA_class_dictionary =  {'AKT inhibitor': 4,\n",
        " 'ATPase inhibitor': 56,\n",
        " 'Aurora kinase inhibitor': 16,\n",
        " 'CC chemokine receptor antagonist': 33,\n",
        " 'CDK inhibitor': 18,\n",
        " 'DNA inhibitor': 63,\n",
        " 'DNA synthesis inhibitor': 26,\n",
        " 'EGFR inhibitor': 53,\n",
        " 'GABA receptor antagonist': 49,\n",
        " 'HCV inhibitor': 0,\n",
        " 'HDAC inhibitor': 22,\n",
        " 'HSP inhibitor': 6,\n",
        " 'JAK inhibitor': 27,\n",
        " 'MEK inhibitor': 37,\n",
        " 'NFkB pathway inhibitor': 3,\n",
        " 'PARP inhibitor': 43,\n",
        " 'PI3K inhibitor': 51,\n",
        " 'PPAR receptor agonist': 58,\n",
        " 'acetylcholine receptor agonist': 44,\n",
        " 'acetylcholine receptor antagonist': 36,\n",
        " 'acetylcholinesterase inhibitor': 19,\n",
        " 'adenosine receptor agonist': 45,\n",
        " 'adenosine receptor antagonist': 65,\n",
        " 'adrenergic receptor agonist': 69,\n",
        " 'adrenergic receptor antagonist': 15,\n",
        " 'angiotensin converting enzyme inhibitor': 8,\n",
        " 'antioxidant': 10,\n",
        " 'apoptosis stimulant': 20,\n",
        " 'bacterial 30S ribosomal subunit inhibitor': 13,\n",
        " 'bacterial 50S ribosomal subunit inhibitor': 17,\n",
        " 'bacterial DNA gyrase inhibitor': 31,\n",
        " 'bacterial cell wall synthesis inhibitor': 30,\n",
        " 'benzodiazepine receptor agonist': 57,\n",
        " 'bromodomain inhibitor': 59,\n",
        " 'calcium channel blocker': 35,\n",
        " 'carbonic anhydrase inhibitor': 50,\n",
        " 'cyclooxygenase inhibitor': 47,\n",
        " 'cytochrome P450 inhibitor': 12,\n",
        " 'dopamine receptor agonist': 54,\n",
        " 'dopamine receptor antagonist': 14,\n",
        " 'tachykinin antagonist': 28,\n",
        " 'estrogen receptor agonist': 52,\n",
        " 'glucocorticoid receptor agonist': 29,\n",
        " 'glutamate receptor agonist': 9,\n",
        " 'glutamate receptor antagonist': 34,\n",
        " 'histamine receptor agonist': 39,\n",
        " 'histamine receptor antagonist': 23,\n",
        " 'histone lysine methyltransferase inhibitor': 21,\n",
        " 'local anesthetic': 41,\n",
        " 'mTOR inhibitor': 62,\n",
        " 'monoamine oxidase inhibitor': 42,\n",
        " 'nitric oxide synthase inhibitor': 66,\n",
        " 'opioid receptor agonist': 40,\n",
        " 'opioid receptor antagonist': 55,\n",
        " 'p38 MAPK inhibitor': 11,\n",
        " 'phosphodiesterase inhibitor': 46,\n",
        " 'potassium channel activator': 1,\n",
        " 'potassium channel blocker': 68,\n",
        " 'progesterone receptor agonist': 67,\n",
        " 'prostanoid receptor antagonist': 48,\n",
        " 'protein synthesis inhibitor': 25,\n",
        " 'purinergic receptor antagonist': 61,\n",
        " 'radiopaque medium': 5,\n",
        " 'retinoid receptor agonist': 60,\n",
        " 'rho associated kinase inhibitor': 2,\n",
        " 'serotonin receptor agonist': 7,\n",
        " 'serotonin receptor antagonist': 32,\n",
        " 'sodium channel blocker': 38,\n",
        " 'topoisomerase inhibitor': 64,\n",
        " 'tubulin polymerization inhibitor': 24}  "
      ],
      "metadata": {
        "id": "hn98U53k9qGt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_classes = list(MOA_class_dictionary.values())\n",
        "sorted_classes.sort() \n",
        "assert sorted_classes == [i for i in range(70)]"
      ],
      "metadata": {
        "id": "ePpqpCUBH0Z-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add classes column \n",
        "df['classes'] = None\n",
        "for i in range(df.shape[0]):\n",
        "  df.iloc[i,2] = MOA_class_dictionary[df.iloc[i,1]]\n",
        "df"
      ],
      "metadata": {
        "id": "7FBAtW0JH0ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "03d8cb50-5a92-4859-e3b0-495910ab6df3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 SMILES  \\\n",
              "0                       Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1   \n",
              "1                  OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N   \n",
              "2           O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12   \n",
              "3            O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1   \n",
              "4     O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...   \n",
              "...                                                 ...   \n",
              "2312  CCn1c(nc2c(ncc(OC[C@H]3CCCNC3)c12)C#CC(C)(C)O)...   \n",
              "2313                CCN(CC)CCCCN1c2ccccc2Oc2ccc(Cl)cc12   \n",
              "2314      CCCCCCCCCCCCCCCCCCOP(O)(=O)OC1CC[N+](C)(C)CC1   \n",
              "2315  Cc1n[nH]c2ccc(cc12)-c1cncc(OC[C@@H](N)Cc2ccccc...   \n",
              "2316  CC(C)NC[C@@H](C(=O)N1CCN(CC1)c1ncnc2[C@@H](O)C...   \n",
              "\n",
              "                                 MOA classes  \n",
              "0     adrenergic receptor antagonist      15  \n",
              "1     adrenergic receptor antagonist      15  \n",
              "2     adrenergic receptor antagonist      15  \n",
              "3     adrenergic receptor antagonist      15  \n",
              "4     adrenergic receptor antagonist      15  \n",
              "...                              ...     ...  \n",
              "2312                   AKT inhibitor       4  \n",
              "2313                   AKT inhibitor       4  \n",
              "2314                   AKT inhibitor       4  \n",
              "2315                   AKT inhibitor       4  \n",
              "2316                   AKT inhibitor       4  \n",
              "\n",
              "[2317 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faa767e0-58ee-409f-83d9-655ee14b66a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2312</th>\n",
              "      <td>CCn1c(nc2c(ncc(OC[C@H]3CCCNC3)c12)C#CC(C)(C)O)...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2313</th>\n",
              "      <td>CCN(CC)CCCCN1c2ccccc2Oc2ccc(Cl)cc12</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2314</th>\n",
              "      <td>CCCCCCCCCCCCCCCCCCOP(O)(=O)OC1CC[N+](C)(C)CC1</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2315</th>\n",
              "      <td>Cc1n[nH]c2ccc(cc12)-c1cncc(OC[C@@H](N)Cc2ccccc...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2316</th>\n",
              "      <td>CC(C)NC[C@@H](C(=O)N1CCN(CC1)c1ncnc2[C@@H](O)C...</td>\n",
              "      <td>AKT inhibitor</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2317 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faa767e0-58ee-409f-83d9-655ee14b66a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-faa767e0-58ee-409f-83d9-655ee14b66a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-faa767e0-58ee-409f-83d9-655ee14b66a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A function that changes smiles string to fingerprints \n",
        "import rdkit\n",
        "import numpy as np\n",
        "from rdkit import *\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "def smiles_to_array_to_string(smiles):\n",
        "  molecules = Chem.MolFromSmiles(smiles) \n",
        "  fingerprints = AllChem.GetMorganFingerprintAsBitVect(molecules, 2)\n",
        "  x_array = []\n",
        "  arrays  = np.zeros(0,)\n",
        "  DataStructs.ConvertToNumpyArray(fingerprints, arrays)\n",
        "  x_array.append(arrays)\n",
        "  x_array = np.asarray(x_array)\n",
        "  x_array = list((np.squeeze(x_array)).astype(int))\n",
        "  string = ''\n",
        "  for i in x_array:\n",
        "    string += str(i) \n",
        "  return string"
      ],
      "metadata": {
        "id": "i63Q50yvIKjC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the existence of Isomers\n",
        "assert len(set([smiles_to_array_to_string(i) for i in df.SMILES.tolist()])) == df.shape[0]"
      ],
      "metadata": {
        "id": "4HEd-M85IKlO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)[['MOA', 'classes', 'SMILES']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "XwpW1wox8fcr",
        "outputId": "3dc2beab-9c56-4305-b6f1-bb692c3fe5e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              MOA classes  \\\n",
              "0  adrenergic receptor antagonist      15   \n",
              "1  adrenergic receptor antagonist      15   \n",
              "2  adrenergic receptor antagonist      15   \n",
              "\n",
              "                                        SMILES  \n",
              "0              Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1  \n",
              "1         OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N  \n",
              "2  O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc203191-fd1a-438d-b778-d60e5d438fa1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MOA</th>\n",
              "      <th>classes</th>\n",
              "      <th>SMILES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "      <td>Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "      <td>OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "      <td>O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc203191-fd1a-438d-b778-d60e5d438fa1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc203191-fd1a-438d-b778-d60e5d438fa1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc203191-fd1a-438d-b778-d60e5d438fa1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split out the test set  \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_valid, x_test, y_train_valid, y_test = train_test_split(df.SMILES, df.classes, test_size =10/100,\n",
        " stratify = df.classes, shuffle = True, random_state = 1000)"
      ],
      "metadata": {
        "id": "LNPAfKr6JI18"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kfold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits = 9)\n",
        "skf.get_n_splits(np.array(list(x_train_valid)), np.array(list(y_train_valid)))\n",
        "train_index_list = []\n",
        "valid_index_list = []\n",
        "for train_index, valid_index in skf.split(np.array(list(x_train_valid)), np.array(list(y_train_valid))):\n",
        "  train_index_list.append(train_index)\n",
        "  valid_index_list.append(valid_index)"
      ],
      "metadata": {
        "id": "47xiERRvJI65"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_kfold = 0 # change the number from 0-8 to get 9 shuffles"
      ],
      "metadata": {
        "id": "0xS6GBsCJWbw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  x_train = list(np.array(list(x_train_valid))[train_index_list[ number_of_kfold ]])\n",
        "  x_valid = list(np.array(list(x_train_valid))[valid_index_list[ number_of_kfold ]])\n",
        "  y_train = list(np.array(list(y_train_valid))[train_index_list[ number_of_kfold ]])\n",
        "  y_valid = list(np.array(list(y_train_valid))[valid_index_list[ number_of_kfold ]])\n",
        "  x_test = list(x_test)\n",
        "  y_test = list(y_test)"
      ],
      "metadata": {
        "id": "BKw3B-kfJWeY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem  # turn to cannoical  smiles\n",
        "x_train = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_train]\n",
        "x_valid = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_valid]\n",
        "x_test = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_test]"
      ],
      "metadata": {
        "id": "GTDbXH1SJWg8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = pd.concat([pd.DataFrame(x_train), pd.DataFrame(y_train),], axis = 1)\n",
        "valid_dataset = pd.concat([pd.DataFrame(x_valid), pd.DataFrame(y_valid),], axis = 1)\n",
        "test_dataset = pd.concat([pd.DataFrame(x_test), pd.DataFrame(y_test),], axis = 1)"
      ],
      "metadata": {
        "id": "ry08TsPB7lnF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.columns = ['smiles','p_np']\n",
        "x_train = list(train_dataset.smiles.tolist())\n",
        "y_train = list(train_dataset.p_np.tolist())"
      ],
      "metadata": {
        "id": "kmAYCS0q_ZZx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "y_unique = np.unique(np.array(y_train))\n",
        "class_weights = class_weight.compute_class_weight(class_weight = 'balanced',classes = y_unique,\n",
        "                       y = np.array(y_train)) \n",
        "class_weights_dict45 = dict(enumerate(class_weights))\n",
        "class_weights_dict45"
      ],
      "metadata": {
        "id": "1dpl1kNJ_Zce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5438fb48-b2d7-4ccb-f330-ea5d980a9d7a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.6544642857142857,\n",
              " 1: 2.205952380952381,\n",
              " 2: 2.205952380952381,\n",
              " 3: 1.8908163265306122,\n",
              " 4: 2.036263736263736,\n",
              " 5: 2.205952380952381,\n",
              " 6: 1.393233082706767,\n",
              " 7: 0.5402332361516035,\n",
              " 8: 1.4706349206349207,\n",
              " 9: 1.3235714285714286,\n",
              " 10: 1.5571428571428572,\n",
              " 11: 1.7647619047619048,\n",
              " 12: 1.4706349206349207,\n",
              " 13: 1.4706349206349207,\n",
              " 14: 0.5190476190476191,\n",
              " 15: 0.34830827067669173,\n",
              " 16: 1.5571428571428572,\n",
              " 17: 1.8908163265306122,\n",
              " 18: 0.9804232804232804,\n",
              " 19: 1.3235714285714286,\n",
              " 20: 2.205952380952381,\n",
              " 21: 1.260544217687075,\n",
              " 22: 0.8539170506912442,\n",
              " 23: 0.47270408163265304,\n",
              " 24: 1.393233082706767,\n",
              " 25: 0.9454081632653061,\n",
              " 26: 1.260544217687075,\n",
              " 27: 1.4706349206349207,\n",
              " 28: 2.205952380952381,\n",
              " 29: 0.7154440154440155,\n",
              " 30: 0.35295238095238096,\n",
              " 31: 1.058857142857143,\n",
              " 32: 0.4812987012987013,\n",
              " 33: 1.1509316770186335,\n",
              " 34: 0.4411904761904762,\n",
              " 35: 0.7154440154440155,\n",
              " 36: 0.4010822510822511,\n",
              " 37: 1.5571428571428572,\n",
              " 38: 0.8539170506912442,\n",
              " 39: 2.205952380952381,\n",
              " 40: 1.393233082706767,\n",
              " 41: 1.393233082706767,\n",
              " 42: 1.3235714285714286,\n",
              " 43: 1.4706349206349207,\n",
              " 44: 0.7563265306122449,\n",
              " 45: 1.5571428571428572,\n",
              " 46: 0.5294285714285715,\n",
              " 47: 0.3350813743218807,\n",
              " 48: 1.7647619047619048,\n",
              " 49: 1.7647619047619048,\n",
              " 50: 1.8908163265306122,\n",
              " 51: 0.7785714285714286,\n",
              " 52: 1.393233082706767,\n",
              " 53: 0.8272321428571429,\n",
              " 54: 0.9454081632653061,\n",
              " 55: 1.7647619047619048,\n",
              " 56: 1.4706349206349207,\n",
              " 57: 0.912807881773399,\n",
              " 58: 1.393233082706767,\n",
              " 59: 1.5571428571428572,\n",
              " 60: 1.6544642857142857,\n",
              " 61: 1.7647619047619048,\n",
              " 62: 1.6544642857142857,\n",
              " 63: 2.036263736263736,\n",
              " 64: 0.912807881773399,\n",
              " 65: 1.2032467532467532,\n",
              " 66: 1.7647619047619048,\n",
              " 67: 1.7647619047619048,\n",
              " 68: 1.393233082706767,\n",
              " 69: 0.3950959488272921}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the tokens \n",
        "x_train_list = []\n",
        "for i in x_train:\n",
        "  x_train_list.append(tokenizer(i)['input_ids'])\n",
        "\n",
        "x_valid_list = []\n",
        "for i in x_valid:\n",
        "  x_valid_list.append(tokenizer(i)['input_ids'])  \n",
        "\n",
        "x_test_list = []\n",
        "for i in x_test:\n",
        "  x_test_list.append(tokenizer(i)['input_ids'])"
      ],
      "metadata": {
        "id": "NqF_TkEp9aQ-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zero padding \n",
        "x_train_list_128 = []\n",
        "for i in x_train_list:\n",
        "  x_train_list_128.append(np.pad(i, (0, 128 - len(i)), 'constant', constant_values = 0))\n",
        "\n",
        "x_valid_list_128 = []\n",
        "for i in x_valid_list:\n",
        "  x_valid_list_128.append(np.pad(i, (0, 128 - len(i)), 'constant', constant_values = 0))\n",
        "\n",
        "x_test_list_128 = []\n",
        "for i in x_test_list:\n",
        "  x_test_list_128.append(np.pad(i, (0, 128 - len(i)), 'constant', constant_values = 0))"
      ],
      "metadata": {
        "id": "ZERQ62tl9ft_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train_list_128)  \n",
        "x_valid = np.array(x_valid_list_128)  \n",
        "x_test = np.array(x_test_list_128) "
      ],
      "metadata": {
        "id": "5U_LuolqbbjA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(y_train).astype(int)\n",
        "y_valid = np.array(y_valid).astype(int)\n",
        "y_test = np.array(y_test).astype(int)"
      ],
      "metadata": {
        "id": "O_sR6BwrrQ5w"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Input, LSTM, Conv1D, Bidirectional, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(2048, output_dim = 128))\n",
        "model.add(Bidirectional(LSTM(128, dropout = 0.5)))\n",
        "model.add(Dropout(0.94))\n",
        "model.add(Dense(len(set(y_train)), activation = 'softmax'))\n",
        "model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "       metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "6YdqrrPAca5V"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath_lstm = '/content/'+'LSTM_top_70_MOA_weights.hdf5'\n",
        "checkpoint_lstm = ModelCheckpoint(filepath_lstm, monitor='val_accuracy', verbose=0, save_best_only=True,\n",
        "                  mode='max')"
      ],
      "metadata": {
        "id": "KKZZuWSHMne6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "gTTM1RrtezYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a5fad2-4a94-4045-ecc3-3ec06536e424"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "263"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping  \n",
        "earlyStopping = EarlyStopping(monitor = 'val_loss', patience = 25, verbose = 0, mode = 'min')\n",
        "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor=0.6, \n",
        "          patience = 7, verbose = 1, min_delta = 1e-119, mode = 'min')\n",
        "history = model.fit(x_train, y_train, validation_data = (x_valid, y_valid), \n",
        "          class_weight = class_weights_dict45, shuffle = True, verbose = 2, epochs = 500,\n",
        "          batch_size = 128, callbacks = [earlyStopping, checkpoint_lstm, reduce_lr_loss])"
      ],
      "metadata": {
        "id": "I48EP50aftnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acaa4470-2669-4ecc-ebf8-7c1bfff6d50d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 - 9s - loss: 4.2507 - accuracy: 0.0140 - val_loss: 4.2438 - val_accuracy: 0.0216 - lr: 0.0010 - 9s/epoch - 619ms/step\n",
            "Epoch 2/500\n",
            "15/15 - 0s - loss: 4.2558 - accuracy: 0.0140 - val_loss: 4.2420 - val_accuracy: 0.0129 - lr: 0.0010 - 374ms/epoch - 25ms/step\n",
            "Epoch 3/500\n",
            "15/15 - 0s - loss: 4.2562 - accuracy: 0.0167 - val_loss: 4.2415 - val_accuracy: 0.0388 - lr: 0.0010 - 410ms/epoch - 27ms/step\n",
            "Epoch 4/500\n",
            "15/15 - 0s - loss: 4.2487 - accuracy: 0.0200 - val_loss: 4.2430 - val_accuracy: 0.0603 - lr: 0.0010 - 407ms/epoch - 27ms/step\n",
            "Epoch 5/500\n",
            "15/15 - 0s - loss: 4.2429 - accuracy: 0.0146 - val_loss: 4.2382 - val_accuracy: 0.0560 - lr: 0.0010 - 375ms/epoch - 25ms/step\n",
            "Epoch 6/500\n",
            "15/15 - 0s - loss: 4.2364 - accuracy: 0.0227 - val_loss: 4.2209 - val_accuracy: 0.0431 - lr: 0.0010 - 373ms/epoch - 25ms/step\n",
            "Epoch 7/500\n",
            "15/15 - 0s - loss: 4.2328 - accuracy: 0.0237 - val_loss: 4.2242 - val_accuracy: 0.0431 - lr: 0.0010 - 374ms/epoch - 25ms/step\n",
            "Epoch 8/500\n",
            "15/15 - 0s - loss: 4.2150 - accuracy: 0.0340 - val_loss: 4.2016 - val_accuracy: 0.0690 - lr: 0.0010 - 408ms/epoch - 27ms/step\n",
            "Epoch 9/500\n",
            "15/15 - 0s - loss: 4.1909 - accuracy: 0.0302 - val_loss: 4.1464 - val_accuracy: 0.0690 - lr: 0.0010 - 376ms/epoch - 25ms/step\n",
            "Epoch 10/500\n",
            "15/15 - 0s - loss: 4.1728 - accuracy: 0.0329 - val_loss: 4.1503 - val_accuracy: 0.0948 - lr: 0.0010 - 414ms/epoch - 28ms/step\n",
            "Epoch 11/500\n",
            "15/15 - 0s - loss: 4.1355 - accuracy: 0.0297 - val_loss: 4.0702 - val_accuracy: 0.0776 - lr: 0.0010 - 374ms/epoch - 25ms/step\n",
            "Epoch 12/500\n",
            "15/15 - 0s - loss: 4.1086 - accuracy: 0.0426 - val_loss: 4.0745 - val_accuracy: 0.0991 - lr: 0.0010 - 411ms/epoch - 27ms/step\n",
            "Epoch 13/500\n",
            "15/15 - 0s - loss: 4.0758 - accuracy: 0.0378 - val_loss: 4.0105 - val_accuracy: 0.0905 - lr: 0.0010 - 371ms/epoch - 25ms/step\n",
            "Epoch 14/500\n",
            "15/15 - 0s - loss: 4.0469 - accuracy: 0.0480 - val_loss: 3.9610 - val_accuracy: 0.1164 - lr: 0.0010 - 404ms/epoch - 27ms/step\n",
            "Epoch 15/500\n",
            "15/15 - 0s - loss: 4.0002 - accuracy: 0.0507 - val_loss: 3.9675 - val_accuracy: 0.1466 - lr: 0.0010 - 409ms/epoch - 27ms/step\n",
            "Epoch 16/500\n",
            "15/15 - 0s - loss: 3.9829 - accuracy: 0.0534 - val_loss: 3.9447 - val_accuracy: 0.1379 - lr: 0.0010 - 382ms/epoch - 25ms/step\n",
            "Epoch 17/500\n",
            "15/15 - 0s - loss: 3.9425 - accuracy: 0.0550 - val_loss: 3.8308 - val_accuracy: 0.1422 - lr: 0.0010 - 375ms/epoch - 25ms/step\n",
            "Epoch 18/500\n",
            "15/15 - 0s - loss: 3.8838 - accuracy: 0.0783 - val_loss: 3.8051 - val_accuracy: 0.1336 - lr: 0.0010 - 375ms/epoch - 25ms/step\n",
            "Epoch 19/500\n",
            "15/15 - 0s - loss: 3.8511 - accuracy: 0.0572 - val_loss: 3.8065 - val_accuracy: 0.1422 - lr: 0.0010 - 370ms/epoch - 25ms/step\n",
            "Epoch 20/500\n",
            "15/15 - 0s - loss: 3.7571 - accuracy: 0.0826 - val_loss: 3.7412 - val_accuracy: 0.1422 - lr: 0.0010 - 374ms/epoch - 25ms/step\n",
            "Epoch 21/500\n",
            "15/15 - 0s - loss: 3.7357 - accuracy: 0.0863 - val_loss: 3.7325 - val_accuracy: 0.1466 - lr: 0.0010 - 375ms/epoch - 25ms/step\n",
            "Epoch 22/500\n",
            "15/15 - 0s - loss: 3.6960 - accuracy: 0.0890 - val_loss: 3.7369 - val_accuracy: 0.1853 - lr: 0.0010 - 409ms/epoch - 27ms/step\n",
            "Epoch 23/500\n",
            "15/15 - 0s - loss: 3.6679 - accuracy: 0.0934 - val_loss: 3.6965 - val_accuracy: 0.1767 - lr: 0.0010 - 376ms/epoch - 25ms/step\n",
            "Epoch 24/500\n",
            "15/15 - 0s - loss: 3.5643 - accuracy: 0.1031 - val_loss: 3.6399 - val_accuracy: 0.1810 - lr: 0.0010 - 373ms/epoch - 25ms/step\n",
            "Epoch 25/500\n",
            "15/15 - 0s - loss: 3.5306 - accuracy: 0.1025 - val_loss: 3.5959 - val_accuracy: 0.1767 - lr: 0.0010 - 375ms/epoch - 25ms/step\n",
            "Epoch 26/500\n",
            "15/15 - 0s - loss: 3.5006 - accuracy: 0.1198 - val_loss: 3.5735 - val_accuracy: 0.1897 - lr: 0.0010 - 413ms/epoch - 28ms/step\n",
            "Epoch 27/500\n",
            "15/15 - 0s - loss: 3.4337 - accuracy: 0.1220 - val_loss: 3.5539 - val_accuracy: 0.1983 - lr: 0.0010 - 409ms/epoch - 27ms/step\n",
            "Epoch 28/500\n",
            "15/15 - 0s - loss: 3.3813 - accuracy: 0.1311 - val_loss: 3.4961 - val_accuracy: 0.2069 - lr: 0.0010 - 406ms/epoch - 27ms/step\n",
            "Epoch 29/500\n",
            "15/15 - 0s - loss: 3.3613 - accuracy: 0.1257 - val_loss: 3.5266 - val_accuracy: 0.1983 - lr: 0.0010 - 374ms/epoch - 25ms/step\n",
            "Epoch 30/500\n",
            "15/15 - 0s - loss: 3.2994 - accuracy: 0.1409 - val_loss: 3.4727 - val_accuracy: 0.2198 - lr: 0.0010 - 409ms/epoch - 27ms/step\n",
            "Epoch 31/500\n",
            "15/15 - 0s - loss: 3.2198 - accuracy: 0.1533 - val_loss: 3.4571 - val_accuracy: 0.2198 - lr: 0.0010 - 372ms/epoch - 25ms/step\n",
            "Epoch 32/500\n",
            "15/15 - 0s - loss: 3.1843 - accuracy: 0.1570 - val_loss: 3.4284 - val_accuracy: 0.2112 - lr: 0.0010 - 371ms/epoch - 25ms/step\n",
            "Epoch 33/500\n",
            "15/15 - 0s - loss: 3.1419 - accuracy: 0.1695 - val_loss: 3.4267 - val_accuracy: 0.1897 - lr: 0.0010 - 374ms/epoch - 25ms/step\n",
            "Epoch 34/500\n",
            "15/15 - 0s - loss: 3.0672 - accuracy: 0.1695 - val_loss: 3.4269 - val_accuracy: 0.2155 - lr: 0.0010 - 375ms/epoch - 25ms/step\n",
            "Epoch 35/500\n",
            "15/15 - 0s - loss: 3.0388 - accuracy: 0.1770 - val_loss: 3.3955 - val_accuracy: 0.2112 - lr: 0.0010 - 372ms/epoch - 25ms/step\n",
            "Epoch 36/500\n",
            "15/15 - 0s - loss: 3.0169 - accuracy: 0.1808 - val_loss: 3.3842 - val_accuracy: 0.2328 - lr: 0.0010 - 407ms/epoch - 27ms/step\n",
            "Epoch 37/500\n",
            "15/15 - 0s - loss: 2.9265 - accuracy: 0.1856 - val_loss: 3.3818 - val_accuracy: 0.2371 - lr: 0.0010 - 407ms/epoch - 27ms/step\n",
            "Epoch 38/500\n",
            "15/15 - 0s - loss: 2.9255 - accuracy: 0.1867 - val_loss: 3.3805 - val_accuracy: 0.2586 - lr: 0.0010 - 405ms/epoch - 27ms/step\n",
            "Epoch 39/500\n",
            "15/15 - 0s - loss: 2.8998 - accuracy: 0.1894 - val_loss: 3.3798 - val_accuracy: 0.2500 - lr: 0.0010 - 373ms/epoch - 25ms/step\n",
            "Epoch 40/500\n",
            "15/15 - 0s - loss: 2.9011 - accuracy: 0.1873 - val_loss: 3.3560 - val_accuracy: 0.2716 - lr: 0.0010 - 408ms/epoch - 27ms/step\n",
            "Epoch 41/500\n",
            "15/15 - 0s - loss: 2.8615 - accuracy: 0.2008 - val_loss: 3.3510 - val_accuracy: 0.2759 - lr: 0.0010 - 408ms/epoch - 27ms/step\n",
            "Epoch 42/500\n",
            "15/15 - 0s - loss: 2.7844 - accuracy: 0.1981 - val_loss: 3.3855 - val_accuracy: 0.2845 - lr: 0.0010 - 410ms/epoch - 27ms/step\n",
            "Epoch 43/500\n",
            "15/15 - 0s - loss: 2.7219 - accuracy: 0.2051 - val_loss: 3.3490 - val_accuracy: 0.2716 - lr: 0.0010 - 375ms/epoch - 25ms/step\n",
            "Epoch 44/500\n",
            "15/15 - 0s - loss: 2.6880 - accuracy: 0.2186 - val_loss: 3.3515 - val_accuracy: 0.2845 - lr: 0.0010 - 375ms/epoch - 25ms/step\n",
            "Epoch 45/500\n",
            "15/15 - 0s - loss: 2.6734 - accuracy: 0.2213 - val_loss: 3.3412 - val_accuracy: 0.2802 - lr: 0.0010 - 374ms/epoch - 25ms/step\n",
            "Epoch 46/500\n",
            "15/15 - 0s - loss: 2.6483 - accuracy: 0.2261 - val_loss: 3.3444 - val_accuracy: 0.3017 - lr: 0.0010 - 407ms/epoch - 27ms/step\n",
            "Epoch 47/500\n",
            "15/15 - 0s - loss: 2.6264 - accuracy: 0.2250 - val_loss: 3.3572 - val_accuracy: 0.2802 - lr: 0.0010 - 377ms/epoch - 25ms/step\n",
            "Epoch 48/500\n",
            "15/15 - 0s - loss: 2.5997 - accuracy: 0.2245 - val_loss: 3.3842 - val_accuracy: 0.2931 - lr: 0.0010 - 376ms/epoch - 25ms/step\n",
            "Epoch 49/500\n",
            "15/15 - 0s - loss: 2.5833 - accuracy: 0.2364 - val_loss: 3.3791 - val_accuracy: 0.2543 - lr: 0.0010 - 377ms/epoch - 25ms/step\n",
            "Epoch 50/500\n",
            "15/15 - 0s - loss: 2.4700 - accuracy: 0.2677 - val_loss: 3.4247 - val_accuracy: 0.2716 - lr: 0.0010 - 372ms/epoch - 25ms/step\n",
            "Epoch 51/500\n",
            "15/15 - 0s - loss: 2.4833 - accuracy: 0.2563 - val_loss: 3.3964 - val_accuracy: 0.2888 - lr: 0.0010 - 376ms/epoch - 25ms/step\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
            "15/15 - 0s - loss: 2.4370 - accuracy: 0.2623 - val_loss: 3.4065 - val_accuracy: 0.2845 - lr: 0.0010 - 375ms/epoch - 25ms/step\n",
            "Epoch 53/500\n",
            "15/15 - 0s - loss: 2.4274 - accuracy: 0.2650 - val_loss: 3.3736 - val_accuracy: 0.2931 - lr: 6.0000e-04 - 371ms/epoch - 25ms/step\n",
            "Epoch 54/500\n",
            "15/15 - 0s - loss: 2.4271 - accuracy: 0.2623 - val_loss: 3.4169 - val_accuracy: 0.2931 - lr: 6.0000e-04 - 373ms/epoch - 25ms/step\n",
            "Epoch 55/500\n",
            "15/15 - 0s - loss: 2.3843 - accuracy: 0.2688 - val_loss: 3.4397 - val_accuracy: 0.2888 - lr: 6.0000e-04 - 371ms/epoch - 25ms/step\n",
            "Epoch 56/500\n",
            "15/15 - 0s - loss: 2.3935 - accuracy: 0.2563 - val_loss: 3.4222 - val_accuracy: 0.2845 - lr: 6.0000e-04 - 371ms/epoch - 25ms/step\n",
            "Epoch 57/500\n",
            "15/15 - 0s - loss: 2.3455 - accuracy: 0.2909 - val_loss: 3.4072 - val_accuracy: 0.2931 - lr: 6.0000e-04 - 374ms/epoch - 25ms/step\n",
            "Epoch 58/500\n",
            "15/15 - 0s - loss: 2.2863 - accuracy: 0.2860 - val_loss: 3.4015 - val_accuracy: 0.2845 - lr: 6.0000e-04 - 375ms/epoch - 25ms/step\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
            "15/15 - 0s - loss: 2.3435 - accuracy: 0.2844 - val_loss: 3.4011 - val_accuracy: 0.2974 - lr: 6.0000e-04 - 372ms/epoch - 25ms/step\n",
            "Epoch 60/500\n",
            "15/15 - 0s - loss: 2.2792 - accuracy: 0.2920 - val_loss: 3.4452 - val_accuracy: 0.2974 - lr: 3.6000e-04 - 372ms/epoch - 25ms/step\n",
            "Epoch 61/500\n",
            "15/15 - 0s - loss: 2.2693 - accuracy: 0.2941 - val_loss: 3.4714 - val_accuracy: 0.2931 - lr: 3.6000e-04 - 371ms/epoch - 25ms/step\n",
            "Epoch 62/500\n",
            "15/15 - 0s - loss: 2.2610 - accuracy: 0.2990 - val_loss: 3.4688 - val_accuracy: 0.2845 - lr: 3.6000e-04 - 378ms/epoch - 25ms/step\n",
            "Epoch 63/500\n",
            "15/15 - 0s - loss: 2.2389 - accuracy: 0.2957 - val_loss: 3.4826 - val_accuracy: 0.2802 - lr: 3.6000e-04 - 374ms/epoch - 25ms/step\n",
            "Epoch 64/500\n",
            "15/15 - 0s - loss: 2.2072 - accuracy: 0.3076 - val_loss: 3.4900 - val_accuracy: 0.2845 - lr: 3.6000e-04 - 374ms/epoch - 25ms/step\n",
            "Epoch 65/500\n",
            "15/15 - 0s - loss: 2.2443 - accuracy: 0.2957 - val_loss: 3.4967 - val_accuracy: 0.2888 - lr: 3.6000e-04 - 380ms/epoch - 25ms/step\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
            "15/15 - 0s - loss: 2.2253 - accuracy: 0.2952 - val_loss: 3.5075 - val_accuracy: 0.2845 - lr: 3.6000e-04 - 377ms/epoch - 25ms/step\n",
            "Epoch 67/500\n",
            "15/15 - 0s - loss: 2.1934 - accuracy: 0.3092 - val_loss: 3.4902 - val_accuracy: 0.2888 - lr: 2.1600e-04 - 375ms/epoch - 25ms/step\n",
            "Epoch 68/500\n",
            "15/15 - 0s - loss: 2.2123 - accuracy: 0.2990 - val_loss: 3.4831 - val_accuracy: 0.2845 - lr: 2.1600e-04 - 374ms/epoch - 25ms/step\n",
            "Epoch 69/500\n",
            "15/15 - 0s - loss: 2.2108 - accuracy: 0.3017 - val_loss: 3.5078 - val_accuracy: 0.2845 - lr: 2.1600e-04 - 373ms/epoch - 25ms/step\n",
            "Epoch 70/500\n",
            "15/15 - 0s - loss: 2.1411 - accuracy: 0.3135 - val_loss: 3.5184 - val_accuracy: 0.2888 - lr: 2.1600e-04 - 375ms/epoch - 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "best_model = load_model(filepath_lstm)"
      ],
      "metadata": {
        "id": "pSfVS5_POy8O"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model \n",
        "from sklearn.metrics import classification_report\n",
        "assert list(y_test)[0:5] == [10, 47, 20, 23, 25]\n",
        "print(classification_report(y_valid, np.array(best_model.predict(x_valid).argmax(-1)),))\n",
        "print(classification_report(y_test, np.array(best_model.predict(x_test).argmax(-1)),))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI2IWPm04MXm",
        "outputId": "3e013877-39af-487f-9974-df789b49b2bb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.50      0.40         2\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       0.50      0.50      0.50         2\n",
            "           7       0.00      0.00      0.00         6\n",
            "           8       0.50      0.33      0.40         3\n",
            "           9       0.22      0.67      0.33         3\n",
            "          10       0.50      0.33      0.40         3\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.00      0.00      0.00         3\n",
            "          13       0.75      1.00      0.86         3\n",
            "          14       0.11      0.17      0.13         6\n",
            "          15       0.17      0.22      0.19         9\n",
            "          16       0.00      0.00      0.00         2\n",
            "          17       1.00      1.00      1.00         2\n",
            "          18       0.50      0.33      0.40         3\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.20      0.50      0.29         2\n",
            "          22       0.33      0.25      0.29         4\n",
            "          23       0.50      0.14      0.22         7\n",
            "          24       0.00      0.00      0.00         3\n",
            "          25       0.00      0.00      0.00         4\n",
            "          26       0.00      0.00      0.00         2\n",
            "          27       0.00      0.00      0.00         2\n",
            "          28       0.33      0.50      0.40         2\n",
            "          29       1.00      1.00      1.00         4\n",
            "          30       0.75      0.90      0.82        10\n",
            "          31       0.33      0.33      0.33         3\n",
            "          32       0.14      0.14      0.14         7\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.00      0.00      0.00         7\n",
            "          35       0.17      0.25      0.20         4\n",
            "          36       0.50      0.44      0.47         9\n",
            "          37       0.33      0.50      0.40         2\n",
            "          38       0.00      0.00      0.00         4\n",
            "          39       0.12      0.50      0.20         2\n",
            "          40       0.11      0.50      0.18         2\n",
            "          41       0.25      0.50      0.33         2\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       0.00      0.00      0.00         2\n",
            "          44       0.33      0.75      0.46         4\n",
            "          45       0.33      1.00      0.50         2\n",
            "          46       0.00      0.00      0.00         6\n",
            "          47       0.42      0.56      0.48         9\n",
            "          48       0.00      0.00      0.00         2\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       1.00      0.50      0.67         4\n",
            "          52       0.00      0.00      0.00         2\n",
            "          53       0.40      0.50      0.44         4\n",
            "          54       0.00      0.00      0.00         4\n",
            "          55       0.67      1.00      0.80         2\n",
            "          56       0.00      0.00      0.00         2\n",
            "          57       0.00      0.00      0.00         3\n",
            "          58       0.00      0.00      0.00         2\n",
            "          59       0.33      0.50      0.40         2\n",
            "          60       1.00      0.50      0.67         2\n",
            "          61       0.00      0.00      0.00         2\n",
            "          62       0.50      0.50      0.50         2\n",
            "          63       0.67      1.00      0.80         2\n",
            "          64       0.00      0.00      0.00         4\n",
            "          65       1.00      0.50      0.67         2\n",
            "          66       0.00      0.00      0.00         2\n",
            "          67       0.67      1.00      0.80         2\n",
            "          68       0.00      0.00      0.00         3\n",
            "          69       0.12      0.12      0.12         8\n",
            "\n",
            "    accuracy                           0.30       232\n",
            "   macro avg       0.26      0.30      0.26       232\n",
            "weighted avg       0.27      0.30      0.27       232\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         2\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.17      0.17      0.17         6\n",
            "           8       0.67      1.00      0.80         2\n",
            "           9       0.67      0.67      0.67         3\n",
            "          10       0.00      0.00      0.00         2\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.00      0.00      0.00         2\n",
            "          13       0.33      0.50      0.40         2\n",
            "          14       0.38      0.50      0.43         6\n",
            "          15       0.23      0.30      0.26        10\n",
            "          16       0.00      0.00      0.00         2\n",
            "          17       0.00      0.00      0.00         2\n",
            "          18       0.00      0.00      0.00         3\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.50      0.67      0.57         3\n",
            "          22       0.25      0.25      0.25         4\n",
            "          23       0.17      0.14      0.15         7\n",
            "          24       1.00      0.50      0.67         2\n",
            "          25       0.00      0.00      0.00         4\n",
            "          26       0.00      0.00      0.00         2\n",
            "          27       0.00      0.00      0.00         2\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       1.00      1.00      1.00         5\n",
            "          30       0.89      0.80      0.84        10\n",
            "          31       1.00      0.67      0.80         3\n",
            "          32       0.25      0.14      0.18         7\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.00      0.00      0.00         7\n",
            "          35       0.33      0.60      0.43         5\n",
            "          36       0.57      0.50      0.53         8\n",
            "          37       0.50      1.00      0.67         2\n",
            "          38       0.00      0.00      0.00         4\n",
            "          39       0.20      0.50      0.29         2\n",
            "          40       0.20      0.50      0.29         2\n",
            "          41       0.14      0.50      0.22         2\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       0.00      0.00      0.00         2\n",
            "          44       0.00      0.00      0.00         4\n",
            "          45       0.14      0.50      0.22         2\n",
            "          46       0.00      0.00      0.00         6\n",
            "          47       0.40      0.20      0.27        10\n",
            "          48       0.00      0.00      0.00         2\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       0.17      0.50      0.25         2\n",
            "          51       0.40      0.50      0.44         4\n",
            "          52       0.00      0.00      0.00         2\n",
            "          53       0.50      0.75      0.60         4\n",
            "          54       0.00      0.00      0.00         4\n",
            "          55       0.00      0.00      0.00         2\n",
            "          56       0.33      0.50      0.40         2\n",
            "          57       0.00      0.00      0.00         3\n",
            "          58       0.50      0.50      0.50         2\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.50      0.50      0.50         2\n",
            "          61       0.00      0.00      0.00         2\n",
            "          62       1.00      0.50      0.67         2\n",
            "          63       0.00      0.00      0.00         2\n",
            "          64       0.40      0.50      0.44         4\n",
            "          65       0.00      0.00      0.00         3\n",
            "          66       0.00      0.00      0.00         2\n",
            "          67       1.00      1.00      1.00         2\n",
            "          68       0.00      0.00      0.00         2\n",
            "          69       0.20      0.25      0.22         8\n",
            "\n",
            "    accuracy                           0.28       232\n",
            "   macro avg       0.23      0.26      0.23       232\n",
            "weighted avg       0.27      0.28      0.27       232\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training curves\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "09gspmb7WkUT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "b21acb07-f176-464f-f86a-2acfe431446a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# References \n",
        "# https://colab.research.google.com/drive/1tsiTpC4i26QNdRzBHFfXIOFVToE54-9b?usp=sharing#scrollTo=UHzrWuFpCtzs\n",
        "# https://github.com/XinhaoLi74/SmilesPE"
      ],
      "metadata": {
        "id": "Bgv_gh6sa38J"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}